{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a2afa8",
   "metadata": {},
   "source": [
    "Première étape on installe les programmes nécéssaires à l'entrainement de l'IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e873265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable-baselines3 in /home/cafekrem/.local/lib/python3.10/site-packages (2.0.0a10)\n",
      "Requirement already satisfied: cloudpickle in /home/cafekrem/.local/lib/python3.10/site-packages (from stable-baselines3) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/cafekrem/.local/lib/python3.10/site-packages (from stable-baselines3) (3.5.2)\n",
      "Requirement already satisfied: torch>=1.11 in /home/cafekrem/.local/lib/python3.10/site-packages (from stable-baselines3) (2.0.1)\n",
      "Requirement already satisfied: pandas in /home/cafekrem/.local/lib/python3.10/site-packages (from stable-baselines3) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/cafekrem/.local/lib/python3.10/site-packages (from stable-baselines3) (1.22.4)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /home/cafekrem/.local/lib/python3.10/site-packages (from stable-baselines3) (0.28.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/cafekrem/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3) (4.6.3)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3) (1.0.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (2.0.0)\n",
      "Requirement already satisfied: filelock in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (3.12.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (11.7.101)\n",
      "Requirement already satisfied: networkx in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.11->stable-baselines3) (3.0.3)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (2.14.3)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.11->stable-baselines3) (1.9)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/cafekrem/.local/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/cafekrem/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/cafekrem/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3) (16.0.5.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib->stable-baselines3) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib->stable-baselines3) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->stable-baselines3) (9.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->stable-baselines3) (2022.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gym in /home/cafekrem/.local/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from gym) (1.22.4)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/cafekrem/.local/lib/python3.10/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from gym) (2.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/cafekrem/.local/lib/python3.10/site-packages (3.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/cafekrem/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3\n",
    "!pip install gym\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52553c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "# On import la librairie gymnasium qu'on renome gym dans le contexte d'execution du fichier\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "# Ici on import de la librairie stable_baselines3 l'object DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a036c",
   "metadata": {},
   "source": [
    "## Environement \n",
    "\n",
    "L'environement est élément avec lequel l'IA va intéragir.\n",
    "Cette environement peut représenter un jeu vidéo, une simulation de déplacement de piéton.\n",
    "\n",
    "Durant ce stage, nous allons utiliser la librairie **gym**. Qui met à disposition à un ensemble d'environement sur lequels nous pouvons entrainer une IA. \n",
    "\n",
    "https://www.gymlibrary.dev/environments/atari/\n",
    "https://www.gymlibrary.dev/environments/mujoco/\n",
    "\n",
    "### CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c93f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fba2c7",
   "metadata": {},
   "source": [
    "Ici on instancie l'environement, il s'agit de l'environement suivant.\n",
    "https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
    "Qui représente un pendule est l'objectif est de ne pas faire tomber le baton.\n",
    "**render_mode** est un argument permetant d'afficher l'environement au sens graphique du terme.\n",
    "\n",
    "le lien ci dessous définit l'ensemble des méthodes de l'environement\n",
    "\n",
    "https://www.gymlibrary.dev/api/core/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966dc9e",
   "metadata": {},
   "source": [
    "### Espace d'action \n",
    "\n",
    "L'environement définit un espace d'action, ça corresponds au action que nous pouvons faire pour interagir avec l'environement.\n",
    "\n",
    "Si on étais sur mario, cela correspondrais au touche de la manette.\n",
    "\n",
    " **action_space** nous définit le type d'action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fae0661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e35dd3",
   "metadata": {},
   "source": [
    "Ici on nous que l'espace d'action est discret, l'opposé de continue ( valeur à virgule, par example la pédale d'accélération d'une voiture )\n",
    "\n",
    "Dans notre cas l'IA peut faire deux choix à tous instant :\n",
    "- aller à droite\n",
    "- aller à gauche "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea354d0a",
   "metadata": {},
   "source": [
    "### Espace d'observation\n",
    "\n",
    "L'espace d'observation, nous donne l'état de l'environement.  \n",
    "\n",
    "Par example avec Mario l'espace d'observation pourrais être l'image du jeu. Grâce à cette image nous savons quand est-ce qu'il faut faire sauter mario ou non. \n",
    "\n",
    "Dans **observation_space**, nous donne les spécification de l'état, à quoi ressemble l'état. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3fb33bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425bd3a",
   "metadata": {},
   "source": [
    "Ici ça parrais complexe à lire, voir moche. \n",
    "\n",
    "C'est pouyr ça que nous allons regarder la documentation, qui est un plus belle.\n",
    "https://www.gymlibrary.dev/environments/classic_control/cart_pole/#observation-space\n",
    "\n",
    "Nous avons donc 4 informations étant des valeur continue :\n",
    "- *cart position* : la position du cart\n",
    "- *Cart Velocity* : la vitesse du cart\n",
    "- *Pole Angle* : l'angle du baton\n",
    "- *Pole Angular Velocity* : la vitesse de chute du baton\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad77c9",
   "metadata": {},
   "source": [
    "\n",
    "#### Donc à partir de ces informations Quelle action prendre Sébastien ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8680dcf",
   "metadata": {},
   "source": [
    "écrit ta réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b0a58",
   "metadata": {},
   "source": [
    "Tu n'en sait rien et bien moi non plus. Et je n'y connais rien en physique. On va donc \"demander\" à l'IA de faire ce choix pour nous. Pour ça on doit définir l'objectif de notre système"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15457683",
   "metadata": {},
   "source": [
    "### Récompense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6db5eb",
   "metadata": {},
   "source": [
    " On peut vulgariser l'entrainement d'une IA à l'aide de la boite de skinner \n",
    " \n",
    " !!! ATTENTION C'EST UNE VULGARISATION !!!!\n",
    " \n",
    " https://fr.wikipedia.org/wiki/Bo%C3%AEte_de_Skinner\n",
    " \n",
    " Vidéo de 3 minutes de la boite de skinner \n",
    " \n",
    " https://www.youtube.com/watch?v=TuT2358C2bU\n",
    " \n",
    " Ainsi on va dirriger le comportement de notre IA en maximisant la fonction récompense. \n",
    " \n",
    " Donc à chaque choix de l'IA l'environement va soit:\n",
    " - le récompenser\n",
    " - le punir\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7abe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, inf)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f799b9",
   "metadata": {},
   "source": [
    "Ici la récompense est continue et varie de - l'infinie à + l'infinie.\n",
    "\n",
    "Si on regarde la documentation à la récompense est 1 si le baton n'est pas tombé sinon 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c48c70",
   "metadata": {},
   "source": [
    "## Deep Reinforcement Learning\n",
    "\n",
    "Afin de déterminer l'action à prendre en fonction de l'état qui maximise la récompense. \n",
    "\n",
    "Pendant ton stage tu va utiliser des solutions de Deep Reinforcement Learning. Tu utiliseras une librairie python **stable_baseline3** qui stocke un ensemble d'algorithm de **deep reinforcement learning**, qui te permettras d'utiliser ces algorithmes comme des boites noires ( au sens où tu ne connais pas le comportement de ces boites )\n",
    "\n",
    "**Deep** veut dire qu'on utilise des réseaux de neuronnes.\n",
    "\n",
    "**Reinforcement Learning** veut dire  qu'on utilise des méthode d'apprentissage basé des récompense cumulative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6551d41",
   "metadata": {},
   "source": [
    "### DQN : Deep Q Network\n",
    "\n",
    "Pendant ton stage tu utiliseras l'algorithm DQN pour Deep Q Network. Au vu du nom ça contiens un réseau de neuronnes. Il reste une lettre à définir le Q.\n",
    "\n",
    "#### Q learning\n",
    "\n",
    "Pour nous allons voir le grand père de cette algorithm le Q learning\n",
    "\n",
    "Voici d'abbord quelques références : \n",
    "- https://www.datacamp.com/tutorial/introduction-q-learning-beginner-tutorial\n",
    "\n",
    "\n",
    "##### Q Table \n",
    "\n",
    "le Q learning ce construit sur une Q table. C'est une tableau à deux dimension. Chaque collones corresponds à une action, chaque ligne à un état. La valeur d'un cases action, état corresponds à l'espérance de récompense pour ce couple. \n",
    "\n",
    "Ainsi le principe du Q learning est de tester beaucoup de combinaison d'état,action afin de remplir ce tableau. Lorsque l'IA devras choisir une action çà l'aide du Q-learning il prendras l'action qui à la plus grande espérance de récompense pour l'état courrant. \n",
    "\n",
    "##### Limites\n",
    "\n",
    "Cependant lorsque l'environement définie un espace d'observation continue ( un angle, une distance ... ). Il faut convertir ces valeur continue en valeur discrète et donc perdre de la précision et avoir un Q table de plus en plus en fonction de la précision voulue. \n",
    "\n",
    "####  DQN \n",
    "\n",
    "Pour pallier à ce problème, on utilise des réseaux de neuronnes permettant d'accepter des valeurs et d'obtenir le compromis forte précision et espace mémoire.\n",
    "\n",
    "Pour sélectionner la meilleur action, le principe reste le même. Le réseau de neuronnes prends en paramètres l'état de l'environement et renvoie pour chaque action l'espérance de récompense. Et donc l'agent choisie l'action avec la plus haute espérance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710a57b",
   "metadata": {},
   "source": [
    "## Entrainement de l'agent\n",
    "\n",
    "Il faut d'abbord commencer par entrainer l'agent/IA. C'est à dire à chaque étape l'agent va prendre un choix et obtenir une récompense puis mettre à jours son réseaux de neuronnes afin de maximiser la récompense.\n",
    "\n",
    "Le code vient de & la docs ce trouve sur :\n",
    "\n",
    "https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html\n",
    "\n",
    "Tu auras des explications sur les paramètres et leur usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e2d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 12827    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 88       |\n",
      "----------------------------------\n",
      "Num timesteps: 100\n",
      "Best mean reward: -inf - Last mean reward per episode: 19.60\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 7394     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 154      |\n",
      "----------------------------------\n",
      "Num timesteps: 200\n",
      "Best mean reward: 19.60 - Last mean reward per episode: 20.56\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 8361     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 249      |\n",
      "----------------------------------\n",
      "Num timesteps: 300\n",
      "Best mean reward: 20.56 - Last mean reward per episode: 21.36\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 9029     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 339      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 9656     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 393      |\n",
      "----------------------------------\n",
      "Num timesteps: 400\n",
      "Best mean reward: 21.36 - Last mean reward per episode: 19.65\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 10155    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 487      |\n",
      "----------------------------------\n",
      "Num timesteps: 500\n",
      "Best mean reward: 21.36 - Last mean reward per episode: 20.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 10480    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 567      |\n",
      "----------------------------------\n",
      "Num timesteps: 600\n",
      "Best mean reward: 21.36 - Last mean reward per episode: 20.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 10697    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 694      |\n",
      "----------------------------------\n",
      "Num timesteps: 700\n",
      "Best mean reward: 21.36 - Last mean reward per episode: 21.69\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "Num timesteps: 800\n",
      "Best mean reward: 21.69 - Last mean reward per episode: 21.91\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 9972     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 806      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 10493    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 891      |\n",
      "----------------------------------\n",
      "Num timesteps: 900\n",
      "Best mean reward: 21.91 - Last mean reward per episode: 22.27\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 10301    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 980      |\n",
      "----------------------------------\n",
      "Num timesteps: 1000\n",
      "Best mean reward: 22.27 - Last mean reward per episode: 22.27\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 10461    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1059     |\n",
      "----------------------------------\n",
      "Num timesteps: 1100\n",
      "Best mean reward: 22.27 - Last mean reward per episode: 21.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 10660    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1166     |\n",
      "----------------------------------\n",
      "Num timesteps: 1200\n",
      "Best mean reward: 22.27 - Last mean reward per episode: 22.30\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 10531    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1233     |\n",
      "----------------------------------\n",
      "Num timesteps: 1300\n",
      "Best mean reward: 22.30 - Last mean reward per episode: 21.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 10566    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1320     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 10850    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1393     |\n",
      "----------------------------------\n",
      "Num timesteps: 1400\n",
      "Best mean reward: 22.30 - Last mean reward per episode: 21.77\n",
      "Num timesteps: 1500\n",
      "Best mean reward: 22.30 - Last mean reward per episode: 22.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 10997    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1519     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 1600\n",
      "Best mean reward: 22.30 - Last mean reward per episode: 22.37\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 11026    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1612     |\n",
      "----------------------------------\n",
      "Num timesteps: 1700\n",
      "Best mean reward: 22.37 - Last mean reward per episode: 22.43\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 11079    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1722     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 11198    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1781     |\n",
      "----------------------------------\n",
      "Num timesteps: 1800\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 22.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 10961    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1844     |\n",
      "----------------------------------\n",
      "Num timesteps: 1900\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.95\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 10971    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1933     |\n",
      "----------------------------------\n",
      "Num timesteps: 2000\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.92\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.981    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 11050    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2008     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 11225    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2077     |\n",
      "----------------------------------\n",
      "Num timesteps: 2100\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 11255    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2154     |\n",
      "----------------------------------\n",
      "Num timesteps: 2200\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 11345    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2232     |\n",
      "----------------------------------\n",
      "Num timesteps: 2300\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.79\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 11428    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2312     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 11526    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2373     |\n",
      "----------------------------------\n",
      "Num timesteps: 2400\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 11563    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2455     |\n",
      "----------------------------------\n",
      "Num timesteps: 2500\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.976    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 11627    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2530     |\n",
      "----------------------------------\n",
      "Num timesteps: 2600\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 11660    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2616     |\n",
      "----------------------------------\n",
      "Num timesteps: 2700\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.62\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 11783    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2717     |\n",
      "----------------------------------\n",
      "Num timesteps: 2800\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 20.82\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 11975    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2853     |\n",
      "----------------------------------\n",
      "Num timesteps: 2900\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.62\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 12032    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2956     |\n",
      "----------------------------------\n",
      "Num timesteps: 3000\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 12050    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3036     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 3100\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.71\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 12100    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3151     |\n",
      "----------------------------------\n",
      "Num timesteps: 3200\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.57\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 12116    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3216     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 12231    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3286     |\n",
      "----------------------------------\n",
      "Num timesteps: 3300\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.20\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 12217    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3377     |\n",
      "----------------------------------\n",
      "Num timesteps: 3400\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 12305    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3484     |\n",
      "----------------------------------\n",
      "Num timesteps: 3500\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.64\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.966    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 12374    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3591     |\n",
      "----------------------------------\n",
      "Num timesteps: 3600\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.98\n",
      "Num timesteps: 3700\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 22.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 12420    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3717     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 12488    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3773     |\n",
      "----------------------------------\n",
      "Num timesteps: 3800\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.57\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 12468    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3869     |\n",
      "----------------------------------\n",
      "Num timesteps: 3900\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.49\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 12452    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3932     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.962    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 12540    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3999     |\n",
      "----------------------------------\n",
      "Num timesteps: 4000\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.55\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 12497    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4070     |\n",
      "----------------------------------\n",
      "Num timesteps: 4100\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 12517    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4151     |\n",
      "----------------------------------\n",
      "Num timesteps: 4200\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.58\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 12569    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4249     |\n",
      "----------------------------------\n",
      "Num timesteps: 4300\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.82\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 12598    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4359     |\n",
      "----------------------------------\n",
      "Num timesteps: 4400\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 22.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 12618    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4441     |\n",
      "----------------------------------\n",
      "Num timesteps: 4500\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 21.90\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.957    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 12619    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4552     |\n",
      "----------------------------------\n",
      "Num timesteps: 4600\n",
      "Best mean reward: 22.43 - Last mean reward per episode: 22.59\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 12575    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4637     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 4700\n",
      "Best mean reward: 22.59 - Last mean reward per episode: 22.74\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 12518    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4744     |\n",
      "----------------------------------\n",
      "Num timesteps: 4800\n",
      "Best mean reward: 22.74 - Last mean reward per episode: 22.89\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.954    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 12523    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4863     |\n",
      "----------------------------------\n",
      "Num timesteps: 4900\n",
      "Best mean reward: 22.89 - Last mean reward per episode: 23.36\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 12459    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4941     |\n",
      "----------------------------------\n",
      "Num timesteps: 5000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 23.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 12499    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5042     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 12454    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5092     |\n",
      "----------------------------------\n",
      "Num timesteps: 5100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 12430    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5158     |\n",
      "----------------------------------\n",
      "Num timesteps: 5200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 12459    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5245     |\n",
      "----------------------------------\n",
      "Num timesteps: 5300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.95     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 12426    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5303     |\n",
      "----------------------------------\n",
      "Num timesteps: 5400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 12509    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5427     |\n",
      "----------------------------------\n",
      "Num timesteps: 5500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 12529    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5524     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.947    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 12590    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5591     |\n",
      "----------------------------------\n",
      "Num timesteps: 5600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 12638    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5694     |\n",
      "----------------------------------\n",
      "Num timesteps: 5700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 12624    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5776     |\n",
      "----------------------------------\n",
      "Num timesteps: 5800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 12599    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5841     |\n",
      "----------------------------------\n",
      "Num timesteps: 5900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 12603    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5902     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 12659    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5973     |\n",
      "----------------------------------\n",
      "Num timesteps: 6000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.08\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.943    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 12618    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6027     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 12674    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6095     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 6100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.96\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 12677    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6178     |\n",
      "----------------------------------\n",
      "Num timesteps: 6200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 12640    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6238     |\n",
      "----------------------------------\n",
      "Num timesteps: 6300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 12657    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6327     |\n",
      "----------------------------------\n",
      "Num timesteps: 6400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.73\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 12594    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6419     |\n",
      "----------------------------------\n",
      "Num timesteps: 6500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 12498    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6500     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 12533    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6598     |\n",
      "----------------------------------\n",
      "Num timesteps: 6600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.46\n",
      "Num timesteps: 6700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.64\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 12520    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6702     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 12489    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6778     |\n",
      "----------------------------------\n",
      "Num timesteps: 6800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 19.78\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 12466    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6879     |\n",
      "----------------------------------\n",
      "Num timesteps: 6900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.17\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 12476    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6993     |\n",
      "----------------------------------\n",
      "Num timesteps: 7000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 12487    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7084     |\n",
      "----------------------------------\n",
      "Num timesteps: 7100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.42\n",
      "Num timesteps: 7200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.08\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 12360    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7200     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 12417    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7291     |\n",
      "----------------------------------\n",
      "Num timesteps: 7300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.33\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 12382    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7367     |\n",
      "----------------------------------\n",
      "Num timesteps: 7400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.23\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 12406    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7456     |\n",
      "----------------------------------\n",
      "Num timesteps: 7500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 12393    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7521     |\n",
      "----------------------------------\n",
      "Num timesteps: 7600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.94\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.928    |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 12413    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7617     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 12456    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7683     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 7700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.92\n",
      "Num timesteps: 7800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 12459    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7832     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 12497    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7891     |\n",
      "----------------------------------\n",
      "Num timesteps: 7900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 12406    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7960     |\n",
      "----------------------------------\n",
      "Num timesteps: 8000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.22\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 12399    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8039     |\n",
      "----------------------------------\n",
      "Num timesteps: 8100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.37\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 12379    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8113     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 12424    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8194     |\n",
      "----------------------------------\n",
      "Num timesteps: 8200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 12412    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8248     |\n",
      "----------------------------------\n",
      "Num timesteps: 8300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.49\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 12435    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8342     |\n",
      "----------------------------------\n",
      "Num timesteps: 8400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.80\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 12411    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8456     |\n",
      "----------------------------------\n",
      "Num timesteps: 8500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 12410    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8526     |\n",
      "----------------------------------\n",
      "Num timesteps: 8600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 12402    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8601     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 12454    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8684     |\n",
      "----------------------------------\n",
      "Num timesteps: 8700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.84\n",
      "Num timesteps: 8800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.69\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 12429    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8803     |\n",
      "----------------------------------\n",
      "Num timesteps: 8900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.99\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 12456    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8905     |\n",
      "----------------------------------\n",
      "Num timesteps: 9000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.32\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 12485    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9021     |\n",
      "----------------------------------\n",
      "Num timesteps: 9100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.21\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 12407    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9100     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 12380    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9167     |\n",
      "----------------------------------\n",
      "Num timesteps: 9200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.55\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 12310    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9222     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 12336    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9276     |\n",
      "----------------------------------\n",
      "Num timesteps: 9300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.76\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.911    |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 12286    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9363     |\n",
      "----------------------------------\n",
      "Num timesteps: 9400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.78\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 12221    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9442     |\n",
      "----------------------------------\n",
      "Num timesteps: 9500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 12214    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9510     |\n",
      "----------------------------------\n",
      "Num timesteps: 9600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.64\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 12238    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9603     |\n",
      "----------------------------------\n",
      "Num timesteps: 9700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 12239    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9701     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 12265    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9759     |\n",
      "----------------------------------\n",
      "Num timesteps: 9800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 12274    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9849     |\n",
      "----------------------------------\n",
      "Num timesteps: 9900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.906    |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 12256    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 9919     |\n",
      "----------------------------------\n",
      "Num timesteps: 10000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.50\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 12283    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10042    |\n",
      "----------------------------------\n",
      "Num timesteps: 10100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 12261    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10118    |\n",
      "----------------------------------\n",
      "Num timesteps: 10200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.05\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 12274    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10213    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 12306    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10276    |\n",
      "----------------------------------\n",
      "Num timesteps: 10300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.82\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 12269    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10355    |\n",
      "----------------------------------\n",
      "Num timesteps: 10400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.11\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.901    |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 12266    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10427    |\n",
      "----------------------------------\n",
      "Num timesteps: 10500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.01\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 12242    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10527    |\n",
      "----------------------------------\n",
      "Num timesteps: 10600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.89\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 12261    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10620    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 12295    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10693    |\n",
      "----------------------------------\n",
      "Num timesteps: 10700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.92\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 12267    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10765    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 10800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 12276    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10839    |\n",
      "----------------------------------\n",
      "Num timesteps: 10900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 12263    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 10950    |\n",
      "----------------------------------\n",
      "Num timesteps: 11000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 12276    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11046    |\n",
      "----------------------------------\n",
      "Num timesteps: 11100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.07\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.894    |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 12291    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11157    |\n",
      "----------------------------------\n",
      "Num timesteps: 11200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 12282    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11230    |\n",
      "----------------------------------\n",
      "Num timesteps: 11300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 20.96\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 12264    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11356    |\n",
      "----------------------------------\n",
      "Num timesteps: 11400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.46\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 12228    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11428    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 12248    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11490    |\n",
      "----------------------------------\n",
      "Num timesteps: 11500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.20\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 12209    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11575    |\n",
      "----------------------------------\n",
      "Num timesteps: 11600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 12218    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11657    |\n",
      "----------------------------------\n",
      "Num timesteps: 11700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 12230    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11775    |\n",
      "----------------------------------\n",
      "Num timesteps: 11800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.55\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 12248    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11864    |\n",
      "----------------------------------\n",
      "Num timesteps: 11900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 12232    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11933    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 12235    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 11999    |\n",
      "----------------------------------\n",
      "Num timesteps: 12000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.50\n",
      "Num timesteps: 12100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 12215    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 12142    |\n",
      "----------------------------------\n",
      "Num timesteps: 12200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 12227    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 12226    |\n",
      "----------------------------------\n",
      "Num timesteps: 12300\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 12223    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12324    |\n",
      "----------------------------------\n",
      "Num timesteps: 12400\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 21.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 12207    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12400    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 12500\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 12213    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12521    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 12240    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12587    |\n",
      "----------------------------------\n",
      "Num timesteps: 12600\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.32\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 12257    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12686    |\n",
      "----------------------------------\n",
      "Num timesteps: 12700\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.879    |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 12248    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12784    |\n",
      "----------------------------------\n",
      "Num timesteps: 12800\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.57\n",
      "Num timesteps: 12900\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 12250    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12908    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 12267    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 12974    |\n",
      "----------------------------------\n",
      "Num timesteps: 13000\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 22.81\n",
      "Num timesteps: 13100\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 23.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 12274    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13103    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 12311    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13196    |\n",
      "----------------------------------\n",
      "Num timesteps: 13200\n",
      "Best mean reward: 23.36 - Last mean reward per episode: 23.57\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "Num timesteps: 13300\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 23.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 12252    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13305    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 12230    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13396    |\n",
      "----------------------------------\n",
      "Num timesteps: 13400\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 23.50\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 12223    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13470    |\n",
      "----------------------------------\n",
      "Num timesteps: 13500\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.99\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 12196    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13544    |\n",
      "----------------------------------\n",
      "Num timesteps: 13600\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.71\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 12190    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13622    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 12194    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13662    |\n",
      "----------------------------------\n",
      "Num timesteps: 13700\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.21\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.87     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 12140    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13723    |\n",
      "----------------------------------\n",
      "Num timesteps: 13800\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.37\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 12145    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13824    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 12160    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13895    |\n",
      "----------------------------------\n",
      "Num timesteps: 13900\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.38\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 12156    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 13958    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 14000\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 21.95\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 12175    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14064    |\n",
      "----------------------------------\n",
      "Num timesteps: 14100\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 21.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 12160    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14126    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 12183    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14190    |\n",
      "----------------------------------\n",
      "Num timesteps: 14200\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 21.91\n",
      "Num timesteps: 14300\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 12167    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14320    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 12195    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14391    |\n",
      "----------------------------------\n",
      "Num timesteps: 14400\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 21.65\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 12197    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14459    |\n",
      "----------------------------------\n",
      "Num timesteps: 14500\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 21.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 12215    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14584    |\n",
      "----------------------------------\n",
      "Num timesteps: 14600\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 21.84\n",
      "Num timesteps: 14700\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 21.97\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 12226    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14719    |\n",
      "----------------------------------\n",
      "Num timesteps: 14800\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.17\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 12250    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14847    |\n",
      "----------------------------------\n",
      "Num timesteps: 14900\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.19\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 12271    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 14967    |\n",
      "----------------------------------\n",
      "Num timesteps: 15000\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 12269    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15074    |\n",
      "----------------------------------\n",
      "Num timesteps: 15100\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 12264    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15124    |\n",
      "----------------------------------\n",
      "Num timesteps: 15200\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.23\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 12285    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15252    |\n",
      "----------------------------------\n",
      "Num timesteps: 15300\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 12308    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15371    |\n",
      "----------------------------------\n",
      "Num timesteps: 15400\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 12306    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15433    |\n",
      "----------------------------------\n",
      "Num timesteps: 15500\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 12294    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15505    |\n",
      "----------------------------------\n",
      "Num timesteps: 15600\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 12309    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15602    |\n",
      "----------------------------------\n",
      "Num timesteps: 15700\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 22.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 12331    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15770    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 15800\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 23.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 12340    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15864    |\n",
      "----------------------------------\n",
      "Num timesteps: 15900\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 23.08\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 12348    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 15960    |\n",
      "----------------------------------\n",
      "Num timesteps: 16000\n",
      "Best mean reward: 23.57 - Last mean reward per episode: 23.66\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 24       |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 12341    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16059    |\n",
      "----------------------------------\n",
      "Num timesteps: 16100\n",
      "Best mean reward: 23.66 - Last mean reward per episode: 24.00\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 24.5     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 12306    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16171    |\n",
      "----------------------------------\n",
      "Num timesteps: 16200\n",
      "Best mean reward: 24.00 - Last mean reward per episode: 24.49\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 24.3     |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 12278    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16251    |\n",
      "----------------------------------\n",
      "Num timesteps: 16300\n",
      "Best mean reward: 24.49 - Last mean reward per episode: 24.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 24.8     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 12287    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16378    |\n",
      "----------------------------------\n",
      "Num timesteps: 16400\n",
      "Best mean reward: 24.49 - Last mean reward per episode: 24.89\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 12245    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16466    |\n",
      "----------------------------------\n",
      "Num timesteps: 16500\n",
      "Best mean reward: 24.89 - Last mean reward per episode: 25.03\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 12233    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16572    |\n",
      "----------------------------------\n",
      "Num timesteps: 16600\n",
      "Best mean reward: 25.03 - Last mean reward per episode: 25.09\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.842    |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 12198    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16647    |\n",
      "----------------------------------\n",
      "Num timesteps: 16700\n",
      "Best mean reward: 25.09 - Last mean reward per episode: 25.23\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 12163    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16712    |\n",
      "----------------------------------\n",
      "Num timesteps: 16800\n",
      "Best mean reward: 25.23 - Last mean reward per episode: 25.25\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 25       |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 12148    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16818    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 25       |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 12161    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 16891    |\n",
      "----------------------------------\n",
      "Num timesteps: 16900\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 25.00\n",
      "Num timesteps: 17000\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 25.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 25.5     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 12147    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17009    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 12173    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17097    |\n",
      "----------------------------------\n",
      "Num timesteps: 17100\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 25.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 24.5     |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 12154    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17171    |\n",
      "----------------------------------\n",
      "Num timesteps: 17200\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 24.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 24       |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 12152    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17243    |\n",
      "----------------------------------\n",
      "Num timesteps: 17300\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 24.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 12109    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17311    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 17400\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 12113    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17447    |\n",
      "----------------------------------\n",
      "Num timesteps: 17500\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.81\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 12115    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17535    |\n",
      "----------------------------------\n",
      "Num timesteps: 17600\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 12109    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17615    |\n",
      "----------------------------------\n",
      "Num timesteps: 17700\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 12076    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17711    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 12091    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17769    |\n",
      "----------------------------------\n",
      "Num timesteps: 17800\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.33\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.831    |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 12086    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17841    |\n",
      "----------------------------------\n",
      "Num timesteps: 17900\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 12084    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 17910    |\n",
      "----------------------------------\n",
      "Num timesteps: 18000\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.09\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 12084    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18015    |\n",
      "----------------------------------\n",
      "Num timesteps: 18100\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 12085    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18107    |\n",
      "----------------------------------\n",
      "Num timesteps: 18200\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 12097    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18202    |\n",
      "----------------------------------\n",
      "Num timesteps: 18300\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 12102    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18309    |\n",
      "----------------------------------\n",
      "Num timesteps: 18400\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 12114    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18403    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 12130    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18468    |\n",
      "----------------------------------\n",
      "Num timesteps: 18500\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 12121    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18557    |\n",
      "----------------------------------\n",
      "Num timesteps: 18600\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 12093    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18648    |\n",
      "----------------------------------\n",
      "Num timesteps: 18700\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.86\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 12084    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18757    |\n",
      "----------------------------------\n",
      "Num timesteps: 18800\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 12062    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18829    |\n",
      "----------------------------------\n",
      "Num timesteps: 18900\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 12068    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 18910    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 19000\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.73\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 12061    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19004    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 12080    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19073    |\n",
      "----------------------------------\n",
      "Num timesteps: 19100\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.78\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 12078    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19131    |\n",
      "----------------------------------\n",
      "Num timesteps: 19200\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 12082    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19235    |\n",
      "----------------------------------\n",
      "Num timesteps: 19300\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 12089    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19320    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 12110    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19394    |\n",
      "----------------------------------\n",
      "Num timesteps: 19400\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.51\n",
      "Num timesteps: 19500\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 12095    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19505    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 12116    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19583    |\n",
      "----------------------------------\n",
      "Num timesteps: 19600\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.22\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 12115    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19645    |\n",
      "----------------------------------\n",
      "Num timesteps: 19700\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.41\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 12121    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19747    |\n",
      "----------------------------------\n",
      "Num timesteps: 19800\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.812    |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 12122    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19804    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 12142    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19884    |\n",
      "----------------------------------\n",
      "Num timesteps: 19900\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 12125    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 19952    |\n",
      "----------------------------------\n",
      "Num timesteps: 20000\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.01\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 12128    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20027    |\n",
      "----------------------------------\n",
      "Num timesteps: 20100\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 12090    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20125    |\n",
      "----------------------------------\n",
      "Num timesteps: 20200\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 12104    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20263    |\n",
      "----------------------------------\n",
      "Num timesteps: 20300\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 12113    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20381    |\n",
      "----------------------------------\n",
      "Num timesteps: 20400\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 12110    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20447    |\n",
      "----------------------------------\n",
      "Num timesteps: 20500\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 12109    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20546    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 20600\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.49\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 12111    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20626    |\n",
      "----------------------------------\n",
      "Num timesteps: 20700\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.803    |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 12073    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20742    |\n",
      "----------------------------------\n",
      "Num timesteps: 20800\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.79\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 12059    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20822    |\n",
      "----------------------------------\n",
      "Num timesteps: 20900\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 12063    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20903    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 12085    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 20988    |\n",
      "----------------------------------\n",
      "Num timesteps: 21000\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 12074    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21081    |\n",
      "----------------------------------\n",
      "Num timesteps: 21100\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.71\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.799    |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 12076    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21161    |\n",
      "----------------------------------\n",
      "Num timesteps: 21200\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.64\n",
      "Num timesteps: 21300\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 21.97\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 12067    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21312    |\n",
      "----------------------------------\n",
      "Num timesteps: 21400\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.73\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 12061    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21404    |\n",
      "----------------------------------\n",
      "Num timesteps: 21500\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.91\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 12068    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21501    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 12081    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21565    |\n",
      "----------------------------------\n",
      "Num timesteps: 21600\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.45\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 12071    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21662    |\n",
      "----------------------------------\n",
      "Num timesteps: 21700\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 22.68\n",
      "Num timesteps: 21800\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 12073    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21806    |\n",
      "----------------------------------\n",
      "Num timesteps: 21900\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.01\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 12085    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 21925    |\n",
      "----------------------------------\n",
      "Num timesteps: 22000\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 12088    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22003    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 12102    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22087    |\n",
      "----------------------------------\n",
      "Num timesteps: 22100\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 12099    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22155    |\n",
      "----------------------------------\n",
      "Num timesteps: 22200\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 12097    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22219    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 22300\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 12087    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22318    |\n",
      "----------------------------------\n",
      "Num timesteps: 22400\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 23.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 12114    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22487    |\n",
      "----------------------------------\n",
      "Num timesteps: 22500\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 24.60\n",
      "Num timesteps: 22600\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 24.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.785    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 12103    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22635    |\n",
      "----------------------------------\n",
      "Num timesteps: 22700\n",
      "Best mean reward: 25.25 - Last mean reward per episode: 25.27\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 12075    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22728    |\n",
      "----------------------------------\n",
      "Num timesteps: 22800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 24.3     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 12076    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22814    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 24.4     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 12086    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 22887    |\n",
      "----------------------------------\n",
      "Num timesteps: 22900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.40\n",
      "Num timesteps: 23000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.56\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 24.8     |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 12091    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23022    |\n",
      "----------------------------------\n",
      "Num timesteps: 23100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 24.8     |\n",
      "|    exploration_rate | 0.781    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 12077    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23105    |\n",
      "----------------------------------\n",
      "Num timesteps: 23200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 24.8     |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 12093    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23226    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 12103    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23287    |\n",
      "----------------------------------\n",
      "Num timesteps: 23300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.65\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.778    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 12094    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23360    |\n",
      "----------------------------------\n",
      "Num timesteps: 23400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.50\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 24.4     |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 12098    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23430    |\n",
      "----------------------------------\n",
      "Num timesteps: 23500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.37\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 24.4     |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 12087    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23516    |\n",
      "----------------------------------\n",
      "Num timesteps: 23600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.23\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 12097    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23616    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.775    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 12110    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23690    |\n",
      "----------------------------------\n",
      "Num timesteps: 23700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 12088    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23747    |\n",
      "----------------------------------\n",
      "Num timesteps: 23800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 12098    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23840    |\n",
      "----------------------------------\n",
      "Num timesteps: 23900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.50\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 12088    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 23944    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 24000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.46\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.772    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 12092    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 24026    |\n",
      "----------------------------------\n",
      "Num timesteps: 24100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.56\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.771    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 12091    |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 24149    |\n",
      "----------------------------------\n",
      "Num timesteps: 24200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 12100    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24242    |\n",
      "----------------------------------\n",
      "Num timesteps: 24300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 12092    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24362    |\n",
      "----------------------------------\n",
      "Num timesteps: 24400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 12083    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24427    |\n",
      "----------------------------------\n",
      "Num timesteps: 24500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.61\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 24.3     |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 12089    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24588    |\n",
      "----------------------------------\n",
      "Num timesteps: 24600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.33\n",
      "Num timesteps: 24700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 25.6     |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 12092    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24774    |\n",
      "----------------------------------\n",
      "Num timesteps: 24800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 25.23\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.764    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 12088    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24835    |\n",
      "----------------------------------\n",
      "Num timesteps: 24900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 12068    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24901    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 12079    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 24959    |\n",
      "----------------------------------\n",
      "Num timesteps: 25000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.96\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 12078    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25035    |\n",
      "----------------------------------\n",
      "Num timesteps: 25100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.98\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.761    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 12078    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25140    |\n",
      "----------------------------------\n",
      "Num timesteps: 25200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.33\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 12081    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25220    |\n",
      "----------------------------------\n",
      "Num timesteps: 25300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 12083    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25348    |\n",
      "----------------------------------\n",
      "Num timesteps: 25400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.08\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 12080    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25409    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 12084    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25463    |\n",
      "----------------------------------\n",
      "Num timesteps: 25500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.20\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 12074    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25515    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.757    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 12088    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25585    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 25600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 12096    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25693    |\n",
      "----------------------------------\n",
      "Num timesteps: 25700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 12090    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25764    |\n",
      "----------------------------------\n",
      "Num timesteps: 25800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 12091    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25845    |\n",
      "----------------------------------\n",
      "Num timesteps: 25900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 12087    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 25945    |\n",
      "----------------------------------\n",
      "Num timesteps: 26000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.76\n",
      "Num timesteps: 26100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 12081    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26107    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 12097    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26190    |\n",
      "----------------------------------\n",
      "Num timesteps: 26200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.50\n",
      "Num timesteps: 26300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.75     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 12087    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26319    |\n",
      "----------------------------------\n",
      "Num timesteps: 26400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.61\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 12091    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26410    |\n",
      "----------------------------------\n",
      "Num timesteps: 26500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 12085    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26504    |\n",
      "----------------------------------\n",
      "Num timesteps: 26600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.76\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 23.9     |\n",
      "|    exploration_rate | 0.747    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 12100    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26636    |\n",
      "----------------------------------\n",
      "Num timesteps: 26700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.94\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 12094    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26738    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 12104    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26799    |\n",
      "----------------------------------\n",
      "Num timesteps: 26800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 12106    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 26894    |\n",
      "----------------------------------\n",
      "Num timesteps: 26900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.06\n",
      "Num timesteps: 27000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.743    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 12096    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27027    |\n",
      "----------------------------------\n",
      "Num timesteps: 27100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.79\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 12091    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27114    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 12105    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27192    |\n",
      "----------------------------------\n",
      "Num timesteps: 27200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.91\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 12110    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27283    |\n",
      "----------------------------------\n",
      "Num timesteps: 27300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.24\n",
      "Num timesteps: 27400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.74     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 12097    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27403    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 12110    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27468    |\n",
      "----------------------------------\n",
      "Num timesteps: 27500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.07\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 12104    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27524    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 12113    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27577    |\n",
      "----------------------------------\n",
      "Num timesteps: 27600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.737    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 12113    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27654    |\n",
      "----------------------------------\n",
      "Num timesteps: 27700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 12119    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27760    |\n",
      "----------------------------------\n",
      "Num timesteps: 27800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 12123    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27862    |\n",
      "----------------------------------\n",
      "Num timesteps: 27900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 12126    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 27954    |\n",
      "----------------------------------\n",
      "Num timesteps: 28000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.45\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 12121    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28031    |\n",
      "----------------------------------\n",
      "Num timesteps: 28100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.733    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 12127    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28116    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 12143    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28199    |\n",
      "----------------------------------\n",
      "Num timesteps: 28200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.54\n",
      "Num timesteps: 28300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 12135    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28308    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 12147    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28375    |\n",
      "----------------------------------\n",
      "Num timesteps: 28400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 12136    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28470    |\n",
      "----------------------------------\n",
      "Num timesteps: 28500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.80\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 12140    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28559    |\n",
      "----------------------------------\n",
      "Num timesteps: 28600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.56\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 12133    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28650    |\n",
      "----------------------------------\n",
      "Num timesteps: 28700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 12132    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28713    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 12124    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28784    |\n",
      "----------------------------------\n",
      "Num timesteps: 28800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 12120    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28862    |\n",
      "----------------------------------\n",
      "Num timesteps: 28900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.725    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 12125    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 28958    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 29000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 12118    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29036    |\n",
      "----------------------------------\n",
      "Num timesteps: 29100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.80\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 12121    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29110    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 12133    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29179    |\n",
      "----------------------------------\n",
      "Num timesteps: 29200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 12126    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29239    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.722    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 12121    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29297    |\n",
      "----------------------------------\n",
      "Num timesteps: 29300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 12098    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29379    |\n",
      "----------------------------------\n",
      "Num timesteps: 29400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 19.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 12098    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29496    |\n",
      "----------------------------------\n",
      "Num timesteps: 29500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 12088    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29564    |\n",
      "----------------------------------\n",
      "Num timesteps: 29600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 12084    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29616    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 12095    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29683    |\n",
      "----------------------------------\n",
      "Num timesteps: 29700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.717    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 12092    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29766    |\n",
      "----------------------------------\n",
      "Num timesteps: 29800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 19.94\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 12100    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29879    |\n",
      "----------------------------------\n",
      "Num timesteps: 29900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.21\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.716    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 12083    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 29944    |\n",
      "----------------------------------\n",
      "Num timesteps: 30000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 12083    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30025    |\n",
      "----------------------------------\n",
      "Num timesteps: 30100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 19.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 12062    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30116    |\n",
      "----------------------------------\n",
      "Num timesteps: 30200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.02\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 12072    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30233    |\n",
      "----------------------------------\n",
      "Num timesteps: 30300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.35\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 12069    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30342    |\n",
      "----------------------------------\n",
      "Num timesteps: 30400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.711    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 12066    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30400    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 12077    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30499    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 30500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.29\n",
      "Num timesteps: 30600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.709    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 12077    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30675    |\n",
      "----------------------------------\n",
      "Num timesteps: 30700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 12056    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30727    |\n",
      "----------------------------------\n",
      "Num timesteps: 30800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 12056    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30802    |\n",
      "----------------------------------\n",
      "Num timesteps: 30900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.706    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 12055    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 30907    |\n",
      "----------------------------------\n",
      "Num timesteps: 31000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.41\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 12067    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31026    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 12065    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31095    |\n",
      "----------------------------------\n",
      "Num timesteps: 31100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.37\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 12063    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31171    |\n",
      "----------------------------------\n",
      "Num timesteps: 31200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.32\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 12057    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31246    |\n",
      "----------------------------------\n",
      "Num timesteps: 31300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 12049    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31310    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.702    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 12060    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31382    |\n",
      "----------------------------------\n",
      "Num timesteps: 31400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 12058    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31457    |\n",
      "----------------------------------\n",
      "Num timesteps: 31500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 12056    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31525    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 12066    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31589    |\n",
      "----------------------------------\n",
      "Num timesteps: 31600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.699    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 12071    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31694    |\n",
      "----------------------------------\n",
      "Num timesteps: 31700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 12067    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31774    |\n",
      "----------------------------------\n",
      "Num timesteps: 31800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.50\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 12061    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31846    |\n",
      "----------------------------------\n",
      "Num timesteps: 31900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.58\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.696    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 12031    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 31949    |\n",
      "----------------------------------\n",
      "Num timesteps: 32000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.80\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 12032    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32079    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 32100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.00\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 12033    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32160    |\n",
      "----------------------------------\n",
      "Num timesteps: 32200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 12029    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32241    |\n",
      "----------------------------------\n",
      "Num timesteps: 32300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.41\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 12033    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32336    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 12025    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32385    |\n",
      "----------------------------------\n",
      "Num timesteps: 32400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.45\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 12005    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32433    |\n",
      "----------------------------------\n",
      "Num timesteps: 32500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.691    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 11990    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32523    |\n",
      "----------------------------------\n",
      "Num timesteps: 32600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.78\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 11985    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32635    |\n",
      "----------------------------------\n",
      "Num timesteps: 32700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.689    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 11977    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32709    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 11991    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32790    |\n",
      "----------------------------------\n",
      "Num timesteps: 32800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.63\n",
      "Num timesteps: 32900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.76\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 11984    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 32912    |\n",
      "----------------------------------\n",
      "Num timesteps: 33000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.98\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 11990    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33004    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 12000    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33075    |\n",
      "----------------------------------\n",
      "Num timesteps: 33100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.685    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 11996    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33140    |\n",
      "----------------------------------\n",
      "Num timesteps: 33200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 11999    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33211    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 12009    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33280    |\n",
      "----------------------------------\n",
      "Num timesteps: 33300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 11986    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33378    |\n",
      "----------------------------------\n",
      "Num timesteps: 33400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 11961    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33463    |\n",
      "----------------------------------\n",
      "Num timesteps: 33500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.86\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.681    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 11941    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33569    |\n",
      "----------------------------------\n",
      "Num timesteps: 33600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.68     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 11922    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33641    |\n",
      "----------------------------------\n",
      "Num timesteps: 33700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.68     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 11903    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33731    |\n",
      "----------------------------------\n",
      "Num timesteps: 33800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.33\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 11887    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33809    |\n",
      "----------------------------------\n",
      "Num timesteps: 33900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 11898    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 33936    |\n",
      "----------------------------------\n",
      "Num timesteps: 34000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.677    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 11893    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34020    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 11904    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34091    |\n",
      "----------------------------------\n",
      "Num timesteps: 34100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 11903    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34147    |\n",
      "----------------------------------\n",
      "Num timesteps: 34200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.69\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 11907    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34256    |\n",
      "----------------------------------\n",
      "Num timesteps: 34300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.00\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.674    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 11905    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34333    |\n",
      "----------------------------------\n",
      "Num timesteps: 34400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.92\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 11912    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34436    |\n",
      "----------------------------------\n",
      "Num timesteps: 34500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 11916    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34542    |\n",
      "----------------------------------\n",
      "Num timesteps: 34600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.78\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 11924    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34646    |\n",
      "----------------------------------\n",
      "Num timesteps: 34700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.94\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 11920    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34774    |\n",
      "----------------------------------\n",
      "Num timesteps: 34800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 11924    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34860    |\n",
      "----------------------------------\n",
      "Num timesteps: 34900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 11904    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 34939    |\n",
      "----------------------------------\n",
      "Num timesteps: 35000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.58\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 11885    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 35046    |\n",
      "----------------------------------\n",
      "Num timesteps: 35100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.41\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.667    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 11881    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 35101    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 11873    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 35166    |\n",
      "----------------------------------\n",
      "Num timesteps: 35200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.665    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 11855    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 35239    |\n",
      "----------------------------------\n",
      "Num timesteps: 35300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.80\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 11851    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 35350    |\n",
      "----------------------------------\n",
      "Num timesteps: 35400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 11847    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 35414    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 11850    |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 35491    |\n",
      "----------------------------------\n",
      "Num timesteps: 35500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.11\n",
      "Num timesteps: 35600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 11817    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 35604    |\n",
      "----------------------------------\n",
      "Num timesteps: 35700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.661    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 11825    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 35702    |\n",
      "----------------------------------\n",
      "Num timesteps: 35800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.66     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 11822    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 35807    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 11834    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 35895    |\n",
      "----------------------------------\n",
      "Num timesteps: 35900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.54\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 11830    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 35950    |\n",
      "----------------------------------\n",
      "Num timesteps: 36000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.92\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 11815    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36009    |\n",
      "----------------------------------\n",
      "Num timesteps: 36100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.657    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 11823    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36124    |\n",
      "----------------------------------\n",
      "Num timesteps: 36200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.80\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 11816    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36200    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.655    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 11826    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36267    |\n",
      "----------------------------------\n",
      "Num timesteps: 36300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.76\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 11832    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36374    |\n",
      "----------------------------------\n",
      "Num timesteps: 36400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 11824    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36431    |\n",
      "----------------------------------\n",
      "Num timesteps: 36500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.75\n",
      "Num timesteps: 36600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 11817    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36612    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 11830    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36698    |\n",
      "----------------------------------\n",
      "Num timesteps: 36700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.62\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 11827    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36770    |\n",
      "----------------------------------\n",
      "Num timesteps: 36800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.65     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 11827    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36841    |\n",
      "----------------------------------\n",
      "Num timesteps: 36900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.57\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 11830    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 36929    |\n",
      "----------------------------------\n",
      "Num timesteps: 37000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 11830    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37017    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 11837    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37078    |\n",
      "----------------------------------\n",
      "Num timesteps: 37100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.17\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 11836    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37134    |\n",
      "----------------------------------\n",
      "Num timesteps: 37200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 11828    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37208    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 11842    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37298    |\n",
      "----------------------------------\n",
      "Num timesteps: 37300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.32\n",
      "Num timesteps: 37400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.62\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.645    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 11841    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37419    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 11852    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37496    |\n",
      "----------------------------------\n",
      "Num timesteps: 37500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.46\n",
      "Num timesteps: 37600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.643    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 11840    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37608    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 11853    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37696    |\n",
      "----------------------------------\n",
      "Num timesteps: 37700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.05\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 11855    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37774    |\n",
      "----------------------------------\n",
      "Num timesteps: 37800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 11849    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37851    |\n",
      "----------------------------------\n",
      "Num timesteps: 37900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.55\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 11847    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 37922    |\n",
      "----------------------------------\n",
      "Num timesteps: 38000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.01\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.639    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 11844    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38004    |\n",
      "----------------------------------\n",
      "Num timesteps: 38100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.638    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 11848    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38103    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 11857    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38172    |\n",
      "----------------------------------\n",
      "Num timesteps: 38200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 11845    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38233    |\n",
      "----------------------------------\n",
      "Num timesteps: 38300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 11841    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38325    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 38400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 11838    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38411    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 11842    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38482    |\n",
      "----------------------------------\n",
      "Num timesteps: 38500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.12\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 11840    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38547    |\n",
      "----------------------------------\n",
      "Num timesteps: 38600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 11847    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38686    |\n",
      "----------------------------------\n",
      "Num timesteps: 38700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.632    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 11850    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38775    |\n",
      "----------------------------------\n",
      "Num timesteps: 38800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 20.82\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 11851    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38874    |\n",
      "----------------------------------\n",
      "Num timesteps: 38900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.06\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.5     |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.63     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 11860    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 38995    |\n",
      "----------------------------------\n",
      "Num timesteps: 39000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.54\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 11857    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39086    |\n",
      "----------------------------------\n",
      "Num timesteps: 39100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.628    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 11861    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39172    |\n",
      "----------------------------------\n",
      "Num timesteps: 39200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.58\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 11871    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39294    |\n",
      "----------------------------------\n",
      "Num timesteps: 39300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.626    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 11872    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39369    |\n",
      "----------------------------------\n",
      "Num timesteps: 39400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 11874    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39451    |\n",
      "----------------------------------\n",
      "Num timesteps: 39500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.625    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 11870    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39505    |\n",
      "----------------------------------\n",
      "Num timesteps: 39600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.90\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 11877    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39624    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.623    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 11883    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39682    |\n",
      "----------------------------------\n",
      "Num timesteps: 39700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.86\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 11881    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39773    |\n",
      "----------------------------------\n",
      "Num timesteps: 39800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.621    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 11888    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39884    |\n",
      "----------------------------------\n",
      "Num timesteps: 39900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 11886    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 39963    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 40000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.07\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 11888    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40042    |\n",
      "----------------------------------\n",
      "Num timesteps: 40100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 11884    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40104    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.618    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 11893    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40182    |\n",
      "----------------------------------\n",
      "Num timesteps: 40200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.81\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.617    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 11896    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40281    |\n",
      "----------------------------------\n",
      "Num timesteps: 40300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.78\n",
      "Num timesteps: 40400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.616    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 11890    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40406    |\n",
      "----------------------------------\n",
      "Num timesteps: 40500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 11896    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40504    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 11905    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40571    |\n",
      "----------------------------------\n",
      "Num timesteps: 40600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 11908    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40665    |\n",
      "----------------------------------\n",
      "Num timesteps: 40700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.613    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 11904    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40727    |\n",
      "----------------------------------\n",
      "Num timesteps: 40800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.50\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.612    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 11899    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40810    |\n",
      "----------------------------------\n",
      "Num timesteps: 40900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 11901    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 40900    |\n",
      "----------------------------------\n",
      "Num timesteps: 41000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.61     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 11899    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41017    |\n",
      "----------------------------------\n",
      "Num timesteps: 41100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.56\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 11903    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41116    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 11908    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41173    |\n",
      "----------------------------------\n",
      "Num timesteps: 41200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.56\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 11906    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41243    |\n",
      "----------------------------------\n",
      "Num timesteps: 41300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 21.76\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.607    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 11916    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41377    |\n",
      "----------------------------------\n",
      "Num timesteps: 41400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.05\n",
      "Num timesteps: 41500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 11913    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41524    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.605    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 11918    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41577    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 41600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.08\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 11901    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41653    |\n",
      "----------------------------------\n",
      "Num timesteps: 41700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.02\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 11907    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41747    |\n",
      "----------------------------------\n",
      "Num timesteps: 41800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.45\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 11909    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41839    |\n",
      "----------------------------------\n",
      "Num timesteps: 41900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.602    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 11915    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 41930    |\n",
      "----------------------------------\n",
      "Num timesteps: 42000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 11915    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42012    |\n",
      "----------------------------------\n",
      "Num timesteps: 42100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 11929    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42174    |\n",
      "----------------------------------\n",
      "Num timesteps: 42200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 22.97\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 11929    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42292    |\n",
      "----------------------------------\n",
      "Num timesteps: 42300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.29\n",
      "Num timesteps: 42400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.597    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 11928    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42403    |\n",
      "----------------------------------\n",
      "Num timesteps: 42500\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 23.94\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.8     |\n",
      "|    ep_rew_mean      | 24.8     |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 11944    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42584    |\n",
      "----------------------------------\n",
      "Num timesteps: 42600\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 24.9     |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 11947    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42667    |\n",
      "----------------------------------\n",
      "Num timesteps: 42700\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.32\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 11945    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42736    |\n",
      "----------------------------------\n",
      "Num timesteps: 42800\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 24.2     |\n",
      "|    exploration_rate | 0.593    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 11947    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42829    |\n",
      "----------------------------------\n",
      "Num timesteps: 42900\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.06\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.592    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 11942    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 42917    |\n",
      "----------------------------------\n",
      "Num timesteps: 43000\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.37\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 11948    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43026    |\n",
      "----------------------------------\n",
      "Num timesteps: 43100\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 24.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 25       |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 11956    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43165    |\n",
      "----------------------------------\n",
      "Num timesteps: 43200\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 25.06\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.589    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 11959    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43246    |\n",
      "----------------------------------\n",
      "Num timesteps: 43300\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 25.27\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 25.6     |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 11969    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43370    |\n",
      "----------------------------------\n",
      "Num timesteps: 43400\n",
      "Best mean reward: 25.27 - Last mean reward per episode: 25.52\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 25.5     |\n",
      "|    exploration_rate | 0.587    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 11959    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43452    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 43500\n",
      "Best mean reward: 25.52 - Last mean reward per episode: 25.38\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 25.6     |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 11967    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43580    |\n",
      "----------------------------------\n",
      "Num timesteps: 43600\n",
      "Best mean reward: 25.52 - Last mean reward per episode: 25.63\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 25.7     |\n",
      "|    exploration_rate | 0.585    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 11962    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43684    |\n",
      "----------------------------------\n",
      "Num timesteps: 43700\n",
      "Best mean reward: 25.63 - Last mean reward per episode: 25.68\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.2     |\n",
      "|    ep_rew_mean      | 26.2     |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 11953    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43789    |\n",
      "----------------------------------\n",
      "Num timesteps: 43800\n",
      "Best mean reward: 25.68 - Last mean reward per episode: 26.16\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.3     |\n",
      "|    ep_rew_mean      | 26.3     |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 11946    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43871    |\n",
      "----------------------------------\n",
      "Num timesteps: 43900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 26.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.7     |\n",
      "|    ep_rew_mean      | 25.7     |\n",
      "|    exploration_rate | 0.583    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 11941    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 43945    |\n",
      "----------------------------------\n",
      "Num timesteps: 44000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 25.17\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 24.9     |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 11942    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44012    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.581    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 11953    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44098    |\n",
      "----------------------------------\n",
      "Num timesteps: 44100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 25.21\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 11946    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44164    |\n",
      "----------------------------------\n",
      "Num timesteps: 44200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 24.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 11951    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44261    |\n",
      "----------------------------------\n",
      "Num timesteps: 44300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 25.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.4     |\n",
      "|    ep_rew_mean      | 25.4     |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 11955    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44377    |\n",
      "----------------------------------\n",
      "Num timesteps: 44400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 25.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.1     |\n",
      "|    ep_rew_mean      | 25.1     |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 11955    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44441    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 24.9     |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 11962    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44499    |\n",
      "----------------------------------\n",
      "Num timesteps: 44500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 24.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 24       |\n",
      "|    exploration_rate | 0.577    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 11960    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44574    |\n",
      "----------------------------------\n",
      "Num timesteps: 44600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.89\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.576    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 11950    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44644    |\n",
      "----------------------------------\n",
      "Num timesteps: 44700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.07\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.575    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 11944    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44718    |\n",
      "----------------------------------\n",
      "Num timesteps: 44800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.00\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 11946    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44805    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 11956    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44884    |\n",
      "----------------------------------\n",
      "Num timesteps: 44900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.17\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 11945    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 44945    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 45000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.05\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.572    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 11945    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45026    |\n",
      "----------------------------------\n",
      "Num timesteps: 45100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.98\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 11940    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45109    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 11950    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45191    |\n",
      "----------------------------------\n",
      "Num timesteps: 45200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.65\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.57     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 11953    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45281    |\n",
      "----------------------------------\n",
      "Num timesteps: 45300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.09\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 11942    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45353    |\n",
      "----------------------------------\n",
      "Num timesteps: 45400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.568    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 11945    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45434    |\n",
      "----------------------------------\n",
      "Num timesteps: 45500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 11953    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45586    |\n",
      "----------------------------------\n",
      "Num timesteps: 45600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.566    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 11953    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45658    |\n",
      "----------------------------------\n",
      "Num timesteps: 45700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.78\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 11950    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45755    |\n",
      "----------------------------------\n",
      "Num timesteps: 45800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.61\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 11953    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45848    |\n",
      "----------------------------------\n",
      "Num timesteps: 45900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 11949    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 45924    |\n",
      "----------------------------------\n",
      "Num timesteps: 46000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.563    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 11939    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46018    |\n",
      "----------------------------------\n",
      "Num timesteps: 46100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.562    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 11941    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46153    |\n",
      "----------------------------------\n",
      "Num timesteps: 46200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.561    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 11945    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46240    |\n",
      "----------------------------------\n",
      "Num timesteps: 46300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.35\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 11947    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46365    |\n",
      "----------------------------------\n",
      "Num timesteps: 46400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.559    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 11948    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46436    |\n",
      "----------------------------------\n",
      "Num timesteps: 46500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.30\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 11945    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46504    |\n",
      "----------------------------------\n",
      "Num timesteps: 46600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.33\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.557    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 11952    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46645    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 46700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.23\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.556    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 11947    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46723    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 11944    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46793    |\n",
      "----------------------------------\n",
      "Num timesteps: 46800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.19\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 11923    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46851    |\n",
      "----------------------------------\n",
      "Num timesteps: 46900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.05\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 11913    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 46909    |\n",
      "----------------------------------\n",
      "Num timesteps: 47000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.96\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 11913    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47009    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 11921    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47094    |\n",
      "----------------------------------\n",
      "Num timesteps: 47100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.552    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 11922    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47189    |\n",
      "----------------------------------\n",
      "Num timesteps: 47200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 11918    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47264    |\n",
      "----------------------------------\n",
      "Num timesteps: 47300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.55     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 11922    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47379    |\n",
      "----------------------------------\n",
      "Num timesteps: 47400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.69\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 11919    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47448    |\n",
      "----------------------------------\n",
      "Num timesteps: 47500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.57\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 11924    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47557    |\n",
      "----------------------------------\n",
      "Num timesteps: 47600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.73\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 11917    |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 47628    |\n",
      "----------------------------------\n",
      "Num timesteps: 47700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 11924    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 47766    |\n",
      "----------------------------------\n",
      "Num timesteps: 47800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 11924    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 47873    |\n",
      "----------------------------------\n",
      "Num timesteps: 47900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.99\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.544    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 11929    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 47971    |\n",
      "----------------------------------\n",
      "Num timesteps: 48000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.79\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 11911    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48057    |\n",
      "----------------------------------\n",
      "Num timesteps: 48100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.92\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 11893    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48130    |\n",
      "----------------------------------\n",
      "Num timesteps: 48200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.68\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 11894    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48201    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.542    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 11899    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48256    |\n",
      "----------------------------------\n",
      "Num timesteps: 48300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.81\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 11897    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48329    |\n",
      "----------------------------------\n",
      "Num timesteps: 48400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 11901    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48449    |\n",
      "----------------------------------\n",
      "Num timesteps: 48500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.539    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 11902    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48554    |\n",
      "----------------------------------\n",
      "Num timesteps: 48600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 11901    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48624    |\n",
      "----------------------------------\n",
      "Num timesteps: 48700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.537    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 11902    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48726    |\n",
      "----------------------------------\n",
      "Num timesteps: 48800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.64\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 11905    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48825    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 11912    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48897    |\n",
      "----------------------------------\n",
      "Num timesteps: 48900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.535    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 11910    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 48980    |\n",
      "----------------------------------\n",
      "Num timesteps: 49000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.87\n",
      "Num timesteps: 49100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.68\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.533    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 11906    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49136    |\n",
      "----------------------------------\n",
      "Num timesteps: 49200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 11903    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49218    |\n",
      "----------------------------------\n",
      "Num timesteps: 49300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 11903    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49309    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.531    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 11910    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49381    |\n",
      "----------------------------------\n",
      "Num timesteps: 49400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 11910    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49471    |\n",
      "----------------------------------\n",
      "Num timesteps: 49500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.82\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 11908    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49555    |\n",
      "----------------------------------\n",
      "Num timesteps: 49600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.64\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.529    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 11905    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49622    |\n",
      "----------------------------------\n",
      "Num timesteps: 49700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.56\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.528    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 11904    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49704    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 11902    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49788    |\n",
      "----------------------------------\n",
      "Num timesteps: 49800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.526    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 11897    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49869    |\n",
      "----------------------------------\n",
      "Num timesteps: 49900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.35\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 11897    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 49954    |\n",
      "----------------------------------\n",
      "Num timesteps: 50000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.86\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 11716    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50030    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.539    |\n",
      "|    n_updates        | 7        |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 11657    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50084    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.531    |\n",
      "|    n_updates        | 20       |\n",
      "----------------------------------\n",
      "Num timesteps: 50100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 11586    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50130    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.511    |\n",
      "|    n_updates        | 32       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 11536    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50187    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.486    |\n",
      "|    n_updates        | 46       |\n",
      "----------------------------------\n",
      "Num timesteps: 50200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.57\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.523    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 11437    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50244    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.457    |\n",
      "|    n_updates        | 60       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 11351    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50294    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.432    |\n",
      "|    n_updates        | 73       |\n",
      "----------------------------------\n",
      "Num timesteps: 50300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.38\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.522    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 11262    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50343    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.401    |\n",
      "|    n_updates        | 85       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 11183    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50393    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 98       |\n",
      "----------------------------------\n",
      "Num timesteps: 50400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 19.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.8     |\n",
      "|    ep_rew_mean      | 18.8     |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 11098    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50437    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 109      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 11034    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50482    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 120      |\n",
      "----------------------------------\n",
      "Num timesteps: 50500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 18.58\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 18.1     |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 10935    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50537    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 134      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.519    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 10859    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50588    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 146      |\n",
      "----------------------------------\n",
      "Num timesteps: 50600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.519    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 10767    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50647    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.238    |\n",
      "|    n_updates        | 161      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 10702    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.25     |\n",
      "|    n_updates        | 173      |\n",
      "----------------------------------\n",
      "Num timesteps: 50700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | 16.2     |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 10613    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50752    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.212    |\n",
      "|    n_updates        | 187      |\n",
      "----------------------------------\n",
      "Num timesteps: 50800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 16.22\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16       |\n",
      "|    ep_rew_mean      | 16       |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 10524    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50816    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 203      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.6     |\n",
      "|    ep_rew_mean      | 15.6     |\n",
      "|    exploration_rate | 0.517    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 10459    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50866    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 216      |\n",
      "----------------------------------\n",
      "Num timesteps: 50900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.55\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.4     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 10387    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 229      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 10325    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 50973    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 243      |\n",
      "----------------------------------\n",
      "Num timesteps: 51000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 10248    |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 51028    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 256      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 10185    |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51083    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0959   |\n",
      "|    n_updates        | 270      |\n",
      "----------------------------------\n",
      "Num timesteps: 51100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.57\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 10111    |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51138    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0663   |\n",
      "|    n_updates        | 284      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.514    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 10047    |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51193    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0547   |\n",
      "|    n_updates        | 298      |\n",
      "----------------------------------\n",
      "Num timesteps: 51200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.05\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 9981     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0574   |\n",
      "|    n_updates        | 311      |\n",
      "----------------------------------\n",
      "Num timesteps: 51300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.65\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 9906     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51305    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.046    |\n",
      "|    n_updates        | 326      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.512    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 9851     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0333   |\n",
      "|    n_updates        | 339      |\n",
      "----------------------------------\n",
      "Num timesteps: 51400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.27\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.511    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 9771     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51427    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0287   |\n",
      "|    n_updates        | 356      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.511    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 9716     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51479    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 369      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 51500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 9655     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51530    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0316   |\n",
      "|    n_updates        | 382      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.51     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 9598     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51582    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 395      |\n",
      "----------------------------------\n",
      "Num timesteps: 51600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.35\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 9535     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51633    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0196   |\n",
      "|    n_updates        | 408      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 9480     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51691    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 422      |\n",
      "----------------------------------\n",
      "Num timesteps: 51700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.508    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 9410     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51753    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 438      |\n",
      "----------------------------------\n",
      "Num timesteps: 51800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.508    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 9359     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 449      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 9288     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51873    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 468      |\n",
      "----------------------------------\n",
      "Num timesteps: 51900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 9226     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51929    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 482      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 9179     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 51977    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 494      |\n",
      "----------------------------------\n",
      "Num timesteps: 52000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 9105     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 52052    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 512      |\n",
      "----------------------------------\n",
      "Num timesteps: 52100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 9045     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 52111    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 527      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 8990     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 52171    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 542      |\n",
      "----------------------------------\n",
      "Num timesteps: 52200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.12\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.504    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 8931     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 52227    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 556      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 8879     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 52287    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0073   |\n",
      "|    n_updates        | 571      |\n",
      "----------------------------------\n",
      "Num timesteps: 52300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.21\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 8816     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 52356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 588      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 52400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.37\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.502    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 8754     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 52417    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00935  |\n",
      "|    n_updates        | 604      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 8699     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52486    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.005    |\n",
      "|    n_updates        | 621      |\n",
      "----------------------------------\n",
      "Num timesteps: 52500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.58\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 8638     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52549    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00744  |\n",
      "|    n_updates        | 637      |\n",
      "----------------------------------\n",
      "Num timesteps: 52600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.69\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 8581     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52610    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 652      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.5      |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 8534     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52670    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 667      |\n",
      "----------------------------------\n",
      "Num timesteps: 52700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.81\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.9     |\n",
      "|    ep_rew_mean      | 14.9     |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 8476     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52737    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00404  |\n",
      "|    n_updates        | 684      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 8444     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52779    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 694      |\n",
      "----------------------------------\n",
      "Num timesteps: 52800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 8391     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52839    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 709      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.498    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 8349     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52894    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 723      |\n",
      "----------------------------------\n",
      "Num timesteps: 52900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 8299     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 52950    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00136  |\n",
      "|    n_updates        | 737      |\n",
      "----------------------------------\n",
      "Num timesteps: 53000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.78\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 8252     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53010    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00276  |\n",
      "|    n_updates        | 752      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 8222     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53052    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00393  |\n",
      "|    n_updates        | 762      |\n",
      "----------------------------------\n",
      "Num timesteps: 53100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.73\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 8182     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53104    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 775      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.495    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 8135     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53165    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00279  |\n",
      "|    n_updates        | 791      |\n",
      "----------------------------------\n",
      "Num timesteps: 53200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.68\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 8092     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53218    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 804      |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 8056     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53272    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 817      |\n",
      "----------------------------------\n",
      "Num timesteps: 53300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 8009     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53334    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 833      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.493    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 7976     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53381    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 845      |\n",
      "----------------------------------\n",
      "Num timesteps: 53400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.492    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 7936     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53431    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 857      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.492    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 7901     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53481    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 870      |\n",
      "----------------------------------\n",
      "Num timesteps: 53500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.27\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 7862     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53536    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00055  |\n",
      "|    n_updates        | 883      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 7818     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53597    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000448 |\n",
      "|    n_updates        | 899      |\n",
      "----------------------------------\n",
      "Num timesteps: 53600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 7771     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53653    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 913      |\n",
      "----------------------------------\n",
      "Num timesteps: 53700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.13\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 7729     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53703    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00174  |\n",
      "|    n_updates        | 925      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 7684     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 53772    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 942      |\n",
      "----------------------------------\n",
      "Num timesteps: 53800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.18\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.489    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 7648     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 53821    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 955      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.488    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 7610     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 53883    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00192  |\n",
      "|    n_updates        | 970      |\n",
      "----------------------------------\n",
      "Num timesteps: 53900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.488    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 7578     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 53927    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 981      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 7546     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 53977    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000671 |\n",
      "|    n_updates        | 994      |\n",
      "----------------------------------\n",
      "Num timesteps: 54000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 7509     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54036    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 1008     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 7481     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54081    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 1020     |\n",
      "----------------------------------\n",
      "Num timesteps: 54100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 7450     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 1031     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 7415     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54189    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 1047     |\n",
      "----------------------------------\n",
      "Num timesteps: 54200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.45\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.485    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 7379     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54248    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00139  |\n",
      "|    n_updates        | 1061     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.484    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 7350     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54298    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000442 |\n",
      "|    n_updates        | 1074     |\n",
      "----------------------------------\n",
      "Num timesteps: 54300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.484    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 7318     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54348    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 1086     |\n",
      "----------------------------------\n",
      "Num timesteps: 54400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 7279     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54405    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000824 |\n",
      "|    n_updates        | 1101     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.483    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 7232     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54459    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000422 |\n",
      "|    n_updates        | 1114     |\n",
      "----------------------------------\n",
      "Num timesteps: 54500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 7188     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54517    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 1129     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 7161     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54564    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 1140     |\n",
      "----------------------------------\n",
      "Num timesteps: 54600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 7122     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54611    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000444 |\n",
      "|    n_updates        | 1152     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 7097     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54657    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000857 |\n",
      "|    n_updates        | 1164     |\n",
      "----------------------------------\n",
      "Num timesteps: 54700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 7066     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54712    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000589 |\n",
      "|    n_updates        | 1177     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.48     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 7041     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54759    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000744 |\n",
      "|    n_updates        | 1189     |\n",
      "----------------------------------\n",
      "Num timesteps: 54800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 7013     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54805    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000495 |\n",
      "|    n_updates        | 1201     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 6987     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54864    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000211 |\n",
      "|    n_updates        | 1215     |\n",
      "----------------------------------\n",
      "Num timesteps: 54900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 6957     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54913    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00104  |\n",
      "|    n_updates        | 1228     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.478    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 6928     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 54979    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000936 |\n",
      "|    n_updates        | 1244     |\n",
      "----------------------------------\n",
      "Num timesteps: 55000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 6903     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 55023    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000499 |\n",
      "|    n_updates        | 1255     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 6881     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55066    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 1266     |\n",
      "----------------------------------\n",
      "Num timesteps: 55100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 6804     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55122    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000345 |\n",
      "|    n_updates        | 1280     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 6712     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55184    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00132  |\n",
      "|    n_updates        | 1295     |\n",
      "----------------------------------\n",
      "Num timesteps: 55200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.99\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 6655     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55232    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000462 |\n",
      "|    n_updates        | 1307     |\n",
      "----------------------------------\n",
      "Num timesteps: 55300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.11\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.475    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 6601     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55311    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00082  |\n",
      "|    n_updates        | 1327     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.474    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 6573     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000476 |\n",
      "|    n_updates        | 1341     |\n",
      "----------------------------------\n",
      "Num timesteps: 55400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.474    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 6539     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55415    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000511 |\n",
      "|    n_updates        | 1353     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 6498     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55461    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000589 |\n",
      "|    n_updates        | 1365     |\n",
      "----------------------------------\n",
      "Num timesteps: 55500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.19\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 6464     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55507    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000397 |\n",
      "|    n_updates        | 1376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 6435     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55556    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000333 |\n",
      "|    n_updates        | 1388     |\n",
      "----------------------------------\n",
      "Num timesteps: 55600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.09\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.472    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 6398     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55612    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000322 |\n",
      "|    n_updates        | 1402     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 6367     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000436 |\n",
      "|    n_updates        | 1416     |\n",
      "----------------------------------\n",
      "Num timesteps: 55700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.20\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 6329     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55722    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000132 |\n",
      "|    n_updates        | 1430     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.47     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 6300     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000587 |\n",
      "|    n_updates        | 1443     |\n",
      "----------------------------------\n",
      "Num timesteps: 55800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.47     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 6268     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55819    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000353 |\n",
      "|    n_updates        | 1454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.469    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 6227     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 55883    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000538 |\n",
      "|    n_updates        | 1470     |\n",
      "----------------------------------\n",
      "Num timesteps: 55900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.22\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.469    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 6193     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 55937    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000144 |\n",
      "|    n_updates        | 1484     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2692     |\n",
      "|    fps              | 6167     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 55988    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000287 |\n",
      "|    n_updates        | 1496     |\n",
      "----------------------------------\n",
      "Num timesteps: 56000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.468    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2696     |\n",
      "|    fps              | 6141     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56030    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00015  |\n",
      "|    n_updates        | 1507     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 6119     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56072    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00013  |\n",
      "|    n_updates        | 1517     |\n",
      "----------------------------------\n",
      "Num timesteps: 56100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2704     |\n",
      "|    fps              | 6081     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56138    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000105 |\n",
      "|    n_updates        | 1534     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2708     |\n",
      "|    fps              | 6060     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56196    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000458 |\n",
      "|    n_updates        | 1548     |\n",
      "----------------------------------\n",
      "Num timesteps: 56200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.32\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.466    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2712     |\n",
      "|    fps              | 6028     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00027  |\n",
      "|    n_updates        | 1564     |\n",
      "----------------------------------\n",
      "Num timesteps: 56300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2716     |\n",
      "|    fps              | 6008     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56306    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00019  |\n",
      "|    n_updates        | 1576     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2720     |\n",
      "|    fps              | 5989     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.63e-05 |\n",
      "|    n_updates        | 1588     |\n",
      "----------------------------------\n",
      "Num timesteps: 56400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.464    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2724     |\n",
      "|    fps              | 5962     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56423    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000453 |\n",
      "|    n_updates        | 1605     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2728     |\n",
      "|    fps              | 5942     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56483    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000347 |\n",
      "|    n_updates        | 1620     |\n",
      "----------------------------------\n",
      "Num timesteps: 56500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.61\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2732     |\n",
      "|    fps              | 5918     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56541    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000506 |\n",
      "|    n_updates        | 1635     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.462    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2736     |\n",
      "|    fps              | 5897     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56593    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.17e-05 |\n",
      "|    n_updates        | 1648     |\n",
      "----------------------------------\n",
      "Num timesteps: 56600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.61\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.462    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2740     |\n",
      "|    fps              | 5876     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56647    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00031  |\n",
      "|    n_updates        | 1661     |\n",
      "----------------------------------\n",
      "Num timesteps: 56700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2744     |\n",
      "|    fps              | 5851     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56710    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000169 |\n",
      "|    n_updates        | 1677     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2748     |\n",
      "|    fps              | 5830     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.86e-05 |\n",
      "|    n_updates        | 1689     |\n",
      "----------------------------------\n",
      "Num timesteps: 56800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.49\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2752     |\n",
      "|    fps              | 5779     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56816    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000747 |\n",
      "|    n_updates        | 1703     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.46     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2756     |\n",
      "|    fps              | 5691     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 56883    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000525 |\n",
      "|    n_updates        | 1720     |\n",
      "----------------------------------\n",
      "Num timesteps: 56900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2760     |\n",
      "|    fps              | 5662     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 56933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00028  |\n",
      "|    n_updates        | 1733     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2764     |\n",
      "|    fps              | 5639     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 56997    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000443 |\n",
      "|    n_updates        | 1749     |\n",
      "----------------------------------\n",
      "Num timesteps: 57000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.85\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2768     |\n",
      "|    fps              | 5619     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57043    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000131 |\n",
      "|    n_updates        | 1760     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.458    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2772     |\n",
      "|    fps              | 5602     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57093    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000406 |\n",
      "|    n_updates        | 1773     |\n",
      "----------------------------------\n",
      "Num timesteps: 57100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.71\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2776     |\n",
      "|    fps              | 5579     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57149    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000365 |\n",
      "|    n_updates        | 1787     |\n",
      "----------------------------------\n",
      "Num timesteps: 57200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.85\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2780     |\n",
      "|    fps              | 5561     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57208    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000102 |\n",
      "|    n_updates        | 1801     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2784     |\n",
      "|    fps              | 5546     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000102 |\n",
      "|    n_updates        | 1814     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 57300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.68\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.456    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2788     |\n",
      "|    fps              | 5531     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57301    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000161 |\n",
      "|    n_updates        | 1825     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.455    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2792     |\n",
      "|    fps              | 5517     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57351    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0005   |\n",
      "|    n_updates        | 1837     |\n",
      "----------------------------------\n",
      "Num timesteps: 57400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.455    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2796     |\n",
      "|    fps              | 5500     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57401    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000407 |\n",
      "|    n_updates        | 1850     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 5483     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57463    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000728 |\n",
      "|    n_updates        | 1865     |\n",
      "----------------------------------\n",
      "Num timesteps: 57500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2804     |\n",
      "|    fps              | 5464     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57524    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000278 |\n",
      "|    n_updates        | 1880     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2808     |\n",
      "|    fps              | 5451     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57571    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000145 |\n",
      "|    n_updates        | 1892     |\n",
      "----------------------------------\n",
      "Num timesteps: 57600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2812     |\n",
      "|    fps              | 5431     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57635    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 1908     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.452    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2816     |\n",
      "|    fps              | 5418     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57682    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000334 |\n",
      "|    n_updates        | 1920     |\n",
      "----------------------------------\n",
      "Num timesteps: 57700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.76\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2820     |\n",
      "|    fps              | 5398     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57748    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00025  |\n",
      "|    n_updates        | 1936     |\n",
      "----------------------------------\n",
      "Num timesteps: 57800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.451    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2824     |\n",
      "|    fps              | 5381     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57807    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000492 |\n",
      "|    n_updates        | 1951     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2828     |\n",
      "|    fps              | 5364     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57864    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000527 |\n",
      "|    n_updates        | 1965     |\n",
      "----------------------------------\n",
      "Num timesteps: 57900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2832     |\n",
      "|    fps              | 5349     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57907    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000173 |\n",
      "|    n_updates        | 1976     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2836     |\n",
      "|    fps              | 5330     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 57957    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000784 |\n",
      "|    n_updates        | 1989     |\n",
      "----------------------------------\n",
      "Num timesteps: 58000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2840     |\n",
      "|    fps              | 5314     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 58010    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000293 |\n",
      "|    n_updates        | 2002     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2844     |\n",
      "|    fps              | 5301     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 58059    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000435 |\n",
      "|    n_updates        | 2014     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 58100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.448    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2848     |\n",
      "|    fps              | 5285     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 58113    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 2028     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2852     |\n",
      "|    fps              | 5271     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58163    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000522 |\n",
      "|    n_updates        | 2040     |\n",
      "----------------------------------\n",
      "Num timesteps: 58200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2856     |\n",
      "|    fps              | 5255     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58209    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000809 |\n",
      "|    n_updates        | 2052     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2860     |\n",
      "|    fps              | 5240     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58261    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000528 |\n",
      "|    n_updates        | 2065     |\n",
      "----------------------------------\n",
      "Num timesteps: 58300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.21\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2864     |\n",
      "|    fps              | 5224     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58310    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000244 |\n",
      "|    n_updates        | 2077     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2868     |\n",
      "|    fps              | 5211     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000329 |\n",
      "|    n_updates        | 2091     |\n",
      "----------------------------------\n",
      "Num timesteps: 58400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.445    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2872     |\n",
      "|    fps              | 5196     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58417    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000355 |\n",
      "|    n_updates        | 2104     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.445    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2876     |\n",
      "|    fps              | 5184     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58465    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000307 |\n",
      "|    n_updates        | 2116     |\n",
      "----------------------------------\n",
      "Num timesteps: 58500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.12\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2880     |\n",
      "|    fps              | 5170     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58524    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000339 |\n",
      "|    n_updates        | 2130     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2884     |\n",
      "|    fps              | 5158     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58573    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000174 |\n",
      "|    n_updates        | 2143     |\n",
      "----------------------------------\n",
      "Num timesteps: 58600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.19\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.443    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2888     |\n",
      "|    fps              | 5145     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58621    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000263 |\n",
      "|    n_updates        | 2155     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.443    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2892     |\n",
      "|    fps              | 5131     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58679    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000813 |\n",
      "|    n_updates        | 2169     |\n",
      "----------------------------------\n",
      "Num timesteps: 58700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2896     |\n",
      "|    fps              | 5118     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58728    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 2181     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2900     |\n",
      "|    fps              | 5108     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58772    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000442 |\n",
      "|    n_updates        | 2192     |\n",
      "----------------------------------\n",
      "Num timesteps: 58800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2904     |\n",
      "|    fps              | 5095     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58813    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000598 |\n",
      "|    n_updates        | 2203     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.441    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2908     |\n",
      "|    fps              | 5082     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58866    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000252 |\n",
      "|    n_updates        | 2216     |\n",
      "----------------------------------\n",
      "Num timesteps: 58900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.81\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2912     |\n",
      "|    fps              | 5069     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58917    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000194 |\n",
      "|    n_updates        | 2229     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2916     |\n",
      "|    fps              | 5056     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 58968    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000425 |\n",
      "|    n_updates        | 2241     |\n",
      "----------------------------------\n",
      "Num timesteps: 59000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.439    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2920     |\n",
      "|    fps              | 5036     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 59035    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000259 |\n",
      "|    n_updates        | 2258     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.439    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2924     |\n",
      "|    fps              | 5023     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 59087    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000153 |\n",
      "|    n_updates        | 2271     |\n",
      "----------------------------------\n",
      "Num timesteps: 59100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2928     |\n",
      "|    fps              | 5009     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 59129    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000408 |\n",
      "|    n_updates        | 2282     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2932     |\n",
      "|    fps              | 4999     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 59168    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000766 |\n",
      "|    n_updates        | 2291     |\n",
      "----------------------------------\n",
      "Num timesteps: 59200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.62\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2936     |\n",
      "|    fps              | 4984     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 59213    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.53e-05 |\n",
      "|    n_updates        | 2303     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2940     |\n",
      "|    fps              | 4971     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 59258    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000104 |\n",
      "|    n_updates        | 2314     |\n",
      "----------------------------------\n",
      "Num timesteps: 59300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.44\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.437    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2944     |\n",
      "|    fps              | 4954     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 59305    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000225 |\n",
      "|    n_updates        | 2326     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2948     |\n",
      "|    fps              | 4942     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59345    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000133 |\n",
      "|    n_updates        | 2336     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2952     |\n",
      "|    fps              | 4928     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59399    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000519 |\n",
      "|    n_updates        | 2349     |\n",
      "----------------------------------\n",
      "Num timesteps: 59400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2956     |\n",
      "|    fps              | 4909     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59457    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000108 |\n",
      "|    n_updates        | 2364     |\n",
      "----------------------------------\n",
      "Num timesteps: 59500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2960     |\n",
      "|    fps              | 4891     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59508    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000359 |\n",
      "|    n_updates        | 2376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2964     |\n",
      "|    fps              | 4877     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59567    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000233 |\n",
      "|    n_updates        | 2391     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 59600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2968     |\n",
      "|    fps              | 4866     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59611    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000384 |\n",
      "|    n_updates        | 2402     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.433    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2972     |\n",
      "|    fps              | 4854     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59672    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000263 |\n",
      "|    n_updates        | 2417     |\n",
      "----------------------------------\n",
      "Num timesteps: 59700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.433    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2976     |\n",
      "|    fps              | 4839     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59729    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000243 |\n",
      "|    n_updates        | 2432     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2980     |\n",
      "|    fps              | 4829     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59777    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000213 |\n",
      "|    n_updates        | 2444     |\n",
      "----------------------------------\n",
      "Num timesteps: 59800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2984     |\n",
      "|    fps              | 4816     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59823    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000191 |\n",
      "|    n_updates        | 2455     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2988     |\n",
      "|    fps              | 4806     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59872    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00028  |\n",
      "|    n_updates        | 2467     |\n",
      "----------------------------------\n",
      "Num timesteps: 59900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.431    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2992     |\n",
      "|    fps              | 4792     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59928    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00061  |\n",
      "|    n_updates        | 2481     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2996     |\n",
      "|    fps              | 4780     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 59983    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000155 |\n",
      "|    n_updates        | 2495     |\n",
      "----------------------------------\n",
      "Num timesteps: 60000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.49\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 4769     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60023    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.393    |\n",
      "|    n_updates        | 2505     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3004     |\n",
      "|    fps              | 4758     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 2519     |\n",
      "----------------------------------\n",
      "Num timesteps: 60100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3008     |\n",
      "|    fps              | 4746     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0995   |\n",
      "|    n_updates        | 2531     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3012     |\n",
      "|    fps              | 4737     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60170    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0597   |\n",
      "|    n_updates        | 2542     |\n",
      "----------------------------------\n",
      "Num timesteps: 60200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.428    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3016     |\n",
      "|    fps              | 4725     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60222    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 2555     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.427    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3020     |\n",
      "|    fps              | 4716     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60274    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0078   |\n",
      "|    n_updates        | 2568     |\n",
      "----------------------------------\n",
      "Num timesteps: 60300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.35\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.427    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3024     |\n",
      "|    fps              | 4705     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60319    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 2579     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3028     |\n",
      "|    fps              | 4695     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60370    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0486   |\n",
      "|    n_updates        | 2592     |\n",
      "----------------------------------\n",
      "Num timesteps: 60400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.38\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3032     |\n",
      "|    fps              | 4684     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60420    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0607   |\n",
      "|    n_updates        | 2604     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3036     |\n",
      "|    fps              | 4675     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60461    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 2615     |\n",
      "----------------------------------\n",
      "Num timesteps: 60500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.46\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3040     |\n",
      "|    fps              | 4665     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 60506    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 2626     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.425    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3044     |\n",
      "|    fps              | 4656     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0376   |\n",
      "|    n_updates        | 2639     |\n",
      "----------------------------------\n",
      "Num timesteps: 60600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.61\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3048     |\n",
      "|    fps              | 4644     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60612    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0351   |\n",
      "|    n_updates        | 2652     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3052     |\n",
      "|    fps              | 4634     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60666    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00176  |\n",
      "|    n_updates        | 2666     |\n",
      "----------------------------------\n",
      "Num timesteps: 60700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3056     |\n",
      "|    fps              | 4622     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60719    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 2679     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.423    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3060     |\n",
      "|    fps              | 4614     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 2689     |\n",
      "----------------------------------\n",
      "Num timesteps: 60800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3064     |\n",
      "|    fps              | 4603     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60814    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0326   |\n",
      "|    n_updates        | 2703     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3068     |\n",
      "|    fps              | 4590     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60890    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 2722     |\n",
      "----------------------------------\n",
      "Num timesteps: 60900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.68\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3072     |\n",
      "|    fps              | 4577     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60942    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00223  |\n",
      "|    n_updates        | 2735     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.421    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3076     |\n",
      "|    fps              | 4568     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 60997    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 2749     |\n",
      "----------------------------------\n",
      "Num timesteps: 61000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.68\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.42     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3080     |\n",
      "|    fps              | 4559     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61042    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00628  |\n",
      "|    n_updates        | 2760     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.42     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3084     |\n",
      "|    fps              | 4552     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61081    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 2770     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 61100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3088     |\n",
      "|    fps              | 4543     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61128    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0272   |\n",
      "|    n_updates        | 2781     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.419    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3092     |\n",
      "|    fps              | 4534     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61179    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 2794     |\n",
      "----------------------------------\n",
      "Num timesteps: 61200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3096     |\n",
      "|    fps              | 4523     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61231    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 2807     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.418    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 4514     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61286    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0524   |\n",
      "|    n_updates        | 2821     |\n",
      "----------------------------------\n",
      "Num timesteps: 61300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.61\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3104     |\n",
      "|    fps              | 4505     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61329    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 2832     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3108     |\n",
      "|    fps              | 4497     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61384    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 2845     |\n",
      "----------------------------------\n",
      "Num timesteps: 61400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.58\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.416    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3112     |\n",
      "|    fps              | 4486     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61440    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 2859     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.416    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3116     |\n",
      "|    fps              | 4477     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61496    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0328   |\n",
      "|    n_updates        | 2873     |\n",
      "----------------------------------\n",
      "Num timesteps: 61500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3120     |\n",
      "|    fps              | 4466     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61556    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 2888     |\n",
      "----------------------------------\n",
      "Num timesteps: 61600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.92\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3124     |\n",
      "|    fps              | 4457     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61607    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0375   |\n",
      "|    n_updates        | 2901     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.414    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3128     |\n",
      "|    fps              | 4450     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61650    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0441   |\n",
      "|    n_updates        | 2912     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.414    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3132     |\n",
      "|    fps              | 4443     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00711  |\n",
      "|    n_updates        | 2923     |\n",
      "----------------------------------\n",
      "Num timesteps: 61700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3136     |\n",
      "|    fps              | 4434     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 2934     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3140     |\n",
      "|    fps              | 4427     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61788    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 2946     |\n",
      "----------------------------------\n",
      "Num timesteps: 61800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.82\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.7     |\n",
      "|    ep_rew_mean      | 12.7     |\n",
      "|    exploration_rate | 0.413    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3144     |\n",
      "|    fps              | 4418     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 61833    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 2958     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.412    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3148     |\n",
      "|    fps              | 4410     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 61887    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0345   |\n",
      "|    n_updates        | 2971     |\n",
      "----------------------------------\n",
      "Num timesteps: 61900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3152     |\n",
      "|    fps              | 4400     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 61948    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0302   |\n",
      "|    n_updates        | 2986     |\n",
      "----------------------------------\n",
      "Num timesteps: 62000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.411    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3156     |\n",
      "|    fps              | 4388     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62009    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0326   |\n",
      "|    n_updates        | 3002     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3160     |\n",
      "|    fps              | 4379     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62065    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0321   |\n",
      "|    n_updates        | 3016     |\n",
      "----------------------------------\n",
      "Num timesteps: 62100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.08\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3164     |\n",
      "|    fps              | 4369     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62117    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 3029     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3168     |\n",
      "|    fps              | 4359     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62192    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 3047     |\n",
      "----------------------------------\n",
      "Num timesteps: 62200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.02\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.409    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3172     |\n",
      "|    fps              | 4349     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 3061     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3176     |\n",
      "|    fps              | 4341     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62298    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0361   |\n",
      "|    n_updates        | 3074     |\n",
      "----------------------------------\n",
      "Num timesteps: 62300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.01\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3180     |\n",
      "|    fps              | 4333     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62348    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0359   |\n",
      "|    n_updates        | 3086     |\n",
      "----------------------------------\n",
      "Num timesteps: 62400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.19\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3184     |\n",
      "|    fps              | 4323     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62402    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00778  |\n",
      "|    n_updates        | 3100     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3188     |\n",
      "|    fps              | 4315     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62468    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 3116     |\n",
      "----------------------------------\n",
      "Num timesteps: 62500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.406    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3192     |\n",
      "|    fps              | 4306     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62519    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 3129     |\n",
      "----------------------------------\n",
      "Num timesteps: 62600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.71\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.405    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3196     |\n",
      "|    fps              | 4292     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62613    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 3153     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.405    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3200     |\n",
      "|    fps              | 4286     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62662    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00843  |\n",
      "|    n_updates        | 3165     |\n",
      "----------------------------------\n",
      "Num timesteps: 62700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3204     |\n",
      "|    fps              | 4278     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62711    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 3177     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 62800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3208     |\n",
      "|    fps              | 4258     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62846    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 3211     |\n",
      "----------------------------------\n",
      "Num timesteps: 62900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3212     |\n",
      "|    fps              | 4249     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62904    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 3225     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.402    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3216     |\n",
      "|    fps              | 4242     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 62952    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 3237     |\n",
      "----------------------------------\n",
      "Num timesteps: 63000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3220     |\n",
      "|    fps              | 4234     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 63001    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 3250     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3224     |\n",
      "|    fps              | 4226     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 63058    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 3264     |\n",
      "----------------------------------\n",
      "Num timesteps: 63100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.4      |\n",
      "| time/               |          |\n",
      "|    episodes         | 3228     |\n",
      "|    fps              | 4217     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 63114    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 3278     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.4      |\n",
      "| time/               |          |\n",
      "|    episodes         | 3232     |\n",
      "|    fps              | 4210     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63169    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.04     |\n",
      "|    n_updates        | 3292     |\n",
      "----------------------------------\n",
      "Num timesteps: 63200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.80\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3236     |\n",
      "|    fps              | 4204     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63215    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 3303     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3240     |\n",
      "|    fps              | 4198     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 3314     |\n",
      "----------------------------------\n",
      "Num timesteps: 63300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.72\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3244     |\n",
      "|    fps              | 4190     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63306    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 3326     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.8     |\n",
      "|    ep_rew_mean      | 14.8     |\n",
      "|    exploration_rate | 0.398    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3248     |\n",
      "|    fps              | 4182     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63371    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.037    |\n",
      "|    n_updates        | 3342     |\n",
      "----------------------------------\n",
      "Num timesteps: 63400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.84\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3252     |\n",
      "|    fps              | 4169     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63471    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 3367     |\n",
      "----------------------------------\n",
      "Num timesteps: 63500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.20\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3256     |\n",
      "|    fps              | 4161     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63527    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0456   |\n",
      "|    n_updates        | 3381     |\n",
      "----------------------------------\n",
      "Num timesteps: 63600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.4     |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3260     |\n",
      "|    fps              | 4150     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63605    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0328   |\n",
      "|    n_updates        | 3401     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.3     |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3264     |\n",
      "|    fps              | 4145     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 3412     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.1     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3268     |\n",
      "|    fps              | 4139     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63698    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 3424     |\n",
      "----------------------------------\n",
      "Num timesteps: 63700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.06\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.1     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3272     |\n",
      "|    fps              | 4130     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63758    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 3439     |\n",
      "----------------------------------\n",
      "Num timesteps: 63800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.1     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.394    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3276     |\n",
      "|    fps              | 4123     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63812    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 3452     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3280     |\n",
      "|    fps              | 4116     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63867    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0604   |\n",
      "|    n_updates        | 3466     |\n",
      "----------------------------------\n",
      "Num timesteps: 63900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.19\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.2     |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3284     |\n",
      "|    fps              | 4109     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63917    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 3479     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3288     |\n",
      "|    fps              | 4103     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 63970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00401  |\n",
      "|    n_updates        | 3492     |\n",
      "----------------------------------\n",
      "Num timesteps: 64000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15       |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.392    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3292     |\n",
      "|    fps              | 4096     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64018    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 3504     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3296     |\n",
      "|    fps              | 4090     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64069    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 3517     |\n",
      "----------------------------------\n",
      "Num timesteps: 64100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.54\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3300     |\n",
      "|    fps              | 4084     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64116    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0301   |\n",
      "|    n_updates        | 3528     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3304     |\n",
      "|    fps              | 4078     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64167    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 3541     |\n",
      "----------------------------------\n",
      "Num timesteps: 64200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3308     |\n",
      "|    fps              | 4070     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64218    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 3554     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.39     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3312     |\n",
      "|    fps              | 4065     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64262    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 3565     |\n",
      "----------------------------------\n",
      "Num timesteps: 64300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.389    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3316     |\n",
      "|    fps              | 4056     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64328    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0442   |\n",
      "|    n_updates        | 3581     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3320     |\n",
      "|    fps              | 4050     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64380    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0045   |\n",
      "|    n_updates        | 3594     |\n",
      "----------------------------------\n",
      "Num timesteps: 64400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.79\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.388    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3324     |\n",
      "|    fps              | 4040     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64446    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 3611     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 64500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.81\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.387    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3328     |\n",
      "|    fps              | 4033     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 64501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 3625     |\n",
      "----------------------------------\n",
      "Num timesteps: 64600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.99\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3332     |\n",
      "|    fps              | 4020     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64601    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 3650     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.386    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3336     |\n",
      "|    fps              | 4013     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 3666     |\n",
      "----------------------------------\n",
      "Num timesteps: 64700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.385    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3340     |\n",
      "|    fps              | 4005     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64721    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 3680     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.385    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3344     |\n",
      "|    fps              | 4000     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64765    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00154  |\n",
      "|    n_updates        | 3691     |\n",
      "----------------------------------\n",
      "Num timesteps: 64800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3348     |\n",
      "|    fps              | 3994     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64805    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 3701     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3352     |\n",
      "|    fps              | 3990     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64847    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 3711     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3356     |\n",
      "|    fps              | 3985     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64890    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 3722     |\n",
      "----------------------------------\n",
      "Num timesteps: 64900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3360     |\n",
      "|    fps              | 3978     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64938    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 3734     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.383    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3364     |\n",
      "|    fps              | 3973     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 64983    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 3745     |\n",
      "----------------------------------\n",
      "Num timesteps: 65000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.33\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.382    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3368     |\n",
      "|    fps              | 3966     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 3759     |\n",
      "----------------------------------\n",
      "Num timesteps: 65100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3372     |\n",
      "|    fps              | 3957     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65106    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 3776     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.381    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3376     |\n",
      "|    fps              | 3952     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65156    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 3788     |\n",
      "----------------------------------\n",
      "Num timesteps: 65200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.50\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3380     |\n",
      "|    fps              | 3944     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 3804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3384     |\n",
      "|    fps              | 3939     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65264    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 3815     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 65300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3388     |\n",
      "|    fps              | 3930     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65336    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 3833     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3392     |\n",
      "|    fps              | 3925     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65388    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0389   |\n",
      "|    n_updates        | 3846     |\n",
      "----------------------------------\n",
      "Num timesteps: 65400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.378    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3396     |\n",
      "|    fps              | 3918     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65445    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 3861     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.378    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3400     |\n",
      "|    fps              | 3912     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65498    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 3874     |\n",
      "----------------------------------\n",
      "Num timesteps: 65500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.82\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3404     |\n",
      "|    fps              | 3903     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65574    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 3893     |\n",
      "----------------------------------\n",
      "Num timesteps: 65600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.376    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3408     |\n",
      "|    fps              | 3893     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 3916     |\n",
      "----------------------------------\n",
      "Num timesteps: 65700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.55\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.376    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3412     |\n",
      "|    fps              | 3886     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65721    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0447   |\n",
      "|    n_updates        | 3930     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.6     |\n",
      "|    ep_rew_mean      | 14.6     |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3416     |\n",
      "|    fps              | 3879     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 65785    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 3946     |\n",
      "----------------------------------\n",
      "Num timesteps: 65800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.54\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3420     |\n",
      "|    fps              | 3872     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 65846    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 3961     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.374    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3424     |\n",
      "|    fps              | 3866     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 65899    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 3974     |\n",
      "----------------------------------\n",
      "Num timesteps: 65900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3428     |\n",
      "|    fps              | 3860     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 65949    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0661   |\n",
      "|    n_updates        | 3987     |\n",
      "----------------------------------\n",
      "Num timesteps: 66000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3432     |\n",
      "|    fps              | 3853     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66012    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 4002     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3436     |\n",
      "|    fps              | 3847     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66068    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0407   |\n",
      "|    n_updates        | 4016     |\n",
      "----------------------------------\n",
      "Num timesteps: 66100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.03\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.372    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3440     |\n",
      "|    fps              | 3840     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66126    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 4031     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3444     |\n",
      "|    fps              | 3835     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 4045     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 66200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.24\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3448     |\n",
      "|    fps              | 3828     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66239    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00672  |\n",
      "|    n_updates        | 4059     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3452     |\n",
      "|    fps              | 3823     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66294    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 4073     |\n",
      "----------------------------------\n",
      "Num timesteps: 66300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.47\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.37     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3456     |\n",
      "|    fps              | 3817     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66336    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 4083     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3460     |\n",
      "|    fps              | 3813     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 4094     |\n",
      "----------------------------------\n",
      "Num timesteps: 66400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.4     |\n",
      "|    ep_rew_mean      | 14.4     |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3464     |\n",
      "|    fps              | 3807     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66422    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 4105     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.3     |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3468     |\n",
      "|    fps              | 3803     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66471    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 4117     |\n",
      "----------------------------------\n",
      "Num timesteps: 66500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.20\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3472     |\n",
      "|    fps              | 3797     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66519    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 4129     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.368    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3476     |\n",
      "|    fps              | 3792     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66566    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0362   |\n",
      "|    n_updates        | 4141     |\n",
      "----------------------------------\n",
      "Num timesteps: 66600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.06\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.1     |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3480     |\n",
      "|    fps              | 3785     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66625    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 4156     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3484     |\n",
      "|    fps              | 3780     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66684    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00867  |\n",
      "|    n_updates        | 4170     |\n",
      "----------------------------------\n",
      "Num timesteps: 66700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3488     |\n",
      "|    fps              | 3774     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66732    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00933  |\n",
      "|    n_updates        | 4182     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.9     |\n",
      "|    ep_rew_mean      | 13.9     |\n",
      "|    exploration_rate | 0.366    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3492     |\n",
      "|    fps              | 3769     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66782    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 4195     |\n",
      "----------------------------------\n",
      "Num timesteps: 66800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.8     |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3496     |\n",
      "|    fps              | 3764     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66824    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 4205     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3500     |\n",
      "|    fps              | 3759     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66866    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 4216     |\n",
      "----------------------------------\n",
      "Num timesteps: 66900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3504     |\n",
      "|    fps              | 3754     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66907    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 4226     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.364    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3508     |\n",
      "|    fps              | 3749     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 66957    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 4239     |\n",
      "----------------------------------\n",
      "Num timesteps: 67000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.84\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3512     |\n",
      "|    fps              | 3744     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 67003    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 4250     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3516     |\n",
      "|    fps              | 3739     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 67063    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00958  |\n",
      "|    n_updates        | 4265     |\n",
      "----------------------------------\n",
      "Num timesteps: 67100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3520     |\n",
      "|    fps              | 3734     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 67105    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 4276     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3524     |\n",
      "|    fps              | 3730     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 67148    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00991  |\n",
      "|    n_updates        | 4286     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.362    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3528     |\n",
      "|    fps              | 3726     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67192    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 4297     |\n",
      "----------------------------------\n",
      "Num timesteps: 67200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.361    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3532     |\n",
      "|    fps              | 3721     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67233    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00237  |\n",
      "|    n_updates        | 4308     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.361    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3536     |\n",
      "|    fps              | 3716     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67285    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 4321     |\n",
      "----------------------------------\n",
      "Num timesteps: 67300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 12.1     |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3540     |\n",
      "|    fps              | 3711     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67333    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00347  |\n",
      "|    n_updates        | 4333     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12       |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3544     |\n",
      "|    fps              | 3707     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 4344     |\n",
      "----------------------------------\n",
      "Num timesteps: 67400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 11.91\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3548     |\n",
      "|    fps              | 3701     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67430    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 4357     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3552     |\n",
      "|    fps              | 3697     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67482    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0346   |\n",
      "|    n_updates        | 4370     |\n",
      "----------------------------------\n",
      "Num timesteps: 67500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 11.89\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.9     |\n",
      "|    ep_rew_mean      | 11.9     |\n",
      "|    exploration_rate | 0.359    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3556     |\n",
      "|    fps              | 3692     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67526    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 4381     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12       |\n",
      "|    ep_rew_mean      | 12       |\n",
      "|    exploration_rate | 0.358    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3560     |\n",
      "|    fps              | 3687     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67582    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 4395     |\n",
      "----------------------------------\n",
      "Num timesteps: 67600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 12.1     |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3564     |\n",
      "|    fps              | 3682     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67632    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 4407     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3568     |\n",
      "|    fps              | 3677     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67686    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 4421     |\n",
      "----------------------------------\n",
      "Num timesteps: 67700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.15\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.1     |\n",
      "|    ep_rew_mean      | 12.1     |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3572     |\n",
      "|    fps              | 3671     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67733    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00743  |\n",
      "|    n_updates        | 4433     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.356    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3576     |\n",
      "|    fps              | 3666     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67797    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 4449     |\n",
      "----------------------------------\n",
      "Num timesteps: 67800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3580     |\n",
      "|    fps              | 3660     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67850    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 4462     |\n",
      "----------------------------------\n",
      "Num timesteps: 67900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3584     |\n",
      "|    fps              | 3655     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67900    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 4474     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.3     |\n",
      "|    ep_rew_mean      | 12.3     |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3588     |\n",
      "|    fps              | 3649     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 67963    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0516   |\n",
      "|    n_updates        | 4490     |\n",
      "----------------------------------\n",
      "Num timesteps: 68000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.354    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3592     |\n",
      "|    fps              | 3643     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68025    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0086   |\n",
      "|    n_updates        | 4506     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3596     |\n",
      "|    fps              | 3639     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68069    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 4517     |\n",
      "----------------------------------\n",
      "Num timesteps: 68100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3600     |\n",
      "|    fps              | 3634     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68122    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 4530     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3604     |\n",
      "|    fps              | 3630     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68171    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 4542     |\n",
      "----------------------------------\n",
      "Num timesteps: 68200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.352    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3608     |\n",
      "|    fps              | 3623     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68247    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 4561     |\n",
      "----------------------------------\n",
      "Num timesteps: 68300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.94\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.351    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3612     |\n",
      "|    fps              | 3613     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68352    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 4587     |\n",
      "----------------------------------\n",
      "Num timesteps: 68400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.40\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3616     |\n",
      "|    fps              | 3608     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68408    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 4601     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3620     |\n",
      "|    fps              | 3603     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 68459    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 4614     |\n",
      "----------------------------------\n",
      "Num timesteps: 68500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.349    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3624     |\n",
      "|    fps              | 3599     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 4625     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.349    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3628     |\n",
      "|    fps              | 3595     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68546    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0469   |\n",
      "|    n_updates        | 4636     |\n",
      "----------------------------------\n",
      "Num timesteps: 68600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.67\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3632     |\n",
      "|    fps              | 3589     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68600    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 4649     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.348    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3636     |\n",
      "|    fps              | 3585     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68646    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 4661     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3640     |\n",
      "|    fps              | 3582     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68693    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 4673     |\n",
      "----------------------------------\n",
      "Num timesteps: 68700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3644     |\n",
      "|    fps              | 3577     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 4684     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3648     |\n",
      "|    fps              | 3573     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 4695     |\n",
      "----------------------------------\n",
      "Num timesteps: 68800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3652     |\n",
      "|    fps              | 3568     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68826    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 4706     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.346    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3656     |\n",
      "|    fps              | 3564     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68877    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 4719     |\n",
      "----------------------------------\n",
      "Num timesteps: 68900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3660     |\n",
      "|    fps              | 3559     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68922    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 4730     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3664     |\n",
      "|    fps              | 3556     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68968    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 4741     |\n",
      "----------------------------------\n",
      "Num timesteps: 69000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.38\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3668     |\n",
      "|    fps              | 3551     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69019    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00818  |\n",
      "|    n_updates        | 4754     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3672     |\n",
      "|    fps              | 3546     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69080    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 4769     |\n",
      "----------------------------------\n",
      "Num timesteps: 69100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.343    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3676     |\n",
      "|    fps              | 3539     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69147    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00377  |\n",
      "|    n_updates        | 4786     |\n",
      "----------------------------------\n",
      "Num timesteps: 69200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3680     |\n",
      "|    fps              | 3534     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69215    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 4803     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3684     |\n",
      "|    fps              | 3530     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69265    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 4816     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 69300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.62\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3688     |\n",
      "|    fps              | 3524     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69328    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0502   |\n",
      "|    n_updates        | 4831     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.341    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3692     |\n",
      "|    fps              | 3520     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69381    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 4845     |\n",
      "----------------------------------\n",
      "Num timesteps: 69400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.60\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3696     |\n",
      "|    fps              | 3515     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69437    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 4859     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3700     |\n",
      "|    fps              | 3511     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 4872     |\n",
      "----------------------------------\n",
      "Num timesteps: 69500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.69\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3704     |\n",
      "|    fps              | 3506     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69536    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 4883     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.339    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3708     |\n",
      "|    fps              | 3502     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69595    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 4898     |\n",
      "----------------------------------\n",
      "Num timesteps: 69600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.48\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3712     |\n",
      "|    fps              | 3495     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69648    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00752  |\n",
      "|    n_updates        | 4911     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3716     |\n",
      "|    fps              | 3491     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69691    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00774  |\n",
      "|    n_updates        | 4922     |\n",
      "----------------------------------\n",
      "Num timesteps: 69700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3720     |\n",
      "|    fps              | 3487     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69736    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 4933     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3724     |\n",
      "|    fps              | 3483     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 69784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 4945     |\n",
      "----------------------------------\n",
      "Num timesteps: 69800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.337    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3728     |\n",
      "|    fps              | 3477     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 69838    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0888   |\n",
      "|    n_updates        | 4959     |\n",
      "----------------------------------\n",
      "Num timesteps: 69900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.97\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.336    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3732     |\n",
      "|    fps              | 3471     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 69902    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 4975     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3736     |\n",
      "|    fps              | 3467     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 69963    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 4990     |\n",
      "----------------------------------\n",
      "Num timesteps: 70000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.21\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3740     |\n",
      "|    fps              | 3461     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70021    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.385    |\n",
      "|    n_updates        | 5005     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3744     |\n",
      "|    fps              | 3457     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70074    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 5018     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 70100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3748     |\n",
      "|    fps              | 3452     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70131    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 5032     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3752     |\n",
      "|    fps              | 3448     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0458   |\n",
      "|    n_updates        | 5045     |\n",
      "----------------------------------\n",
      "Num timesteps: 70200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.51\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.333    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3756     |\n",
      "|    fps              | 3444     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70225    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0877   |\n",
      "|    n_updates        | 5056     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3760     |\n",
      "|    fps              | 3441     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70264    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.036    |\n",
      "|    n_updates        | 5065     |\n",
      "----------------------------------\n",
      "Num timesteps: 70300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.39\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3764     |\n",
      "|    fps              | 3437     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70307    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0475   |\n",
      "|    n_updates        | 5076     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.4     |\n",
      "|    ep_rew_mean      | 13.4     |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3768     |\n",
      "|    fps              | 3433     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70355    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0558   |\n",
      "|    n_updates        | 5088     |\n",
      "----------------------------------\n",
      "Num timesteps: 70400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3772     |\n",
      "|    fps              | 3428     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70407    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 5101     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.331    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3776     |\n",
      "|    fps              | 3424     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70453    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0885   |\n",
      "|    n_updates        | 5113     |\n",
      "----------------------------------\n",
      "Num timesteps: 70500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.88\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3780     |\n",
      "|    fps              | 3420     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.08     |\n",
      "|    n_updates        | 5125     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3784     |\n",
      "|    fps              | 3416     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70556    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 5138     |\n",
      "----------------------------------\n",
      "Num timesteps: 70600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.83\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.329    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3788     |\n",
      "|    fps              | 3410     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70613    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0976   |\n",
      "|    n_updates        | 5153     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.329    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3792     |\n",
      "|    fps              | 3406     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70669    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0938   |\n",
      "|    n_updates        | 5167     |\n",
      "----------------------------------\n",
      "Num timesteps: 70700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 12.89\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.9     |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3796     |\n",
      "|    fps              | 3401     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70727    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 5181     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3800     |\n",
      "|    fps              | 3396     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70795    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0702   |\n",
      "|    n_updates        | 5198     |\n",
      "----------------------------------\n",
      "Num timesteps: 70800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.327    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3804     |\n",
      "|    fps              | 3391     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70856    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 5213     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 70900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.20\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3808     |\n",
      "|    fps              | 3386     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70910    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0303   |\n",
      "|    n_updates        | 5227     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.2     |\n",
      "|    ep_rew_mean      | 13.2     |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3812     |\n",
      "|    fps              | 3382     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70971    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0912   |\n",
      "|    n_updates        | 5242     |\n",
      "----------------------------------\n",
      "Num timesteps: 71000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.6     |\n",
      "|    ep_rew_mean      | 13.6     |\n",
      "|    exploration_rate | 0.325    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3816     |\n",
      "|    fps              | 3375     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71049    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 5262     |\n",
      "----------------------------------\n",
      "Num timesteps: 71100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 13.87\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.324    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3820     |\n",
      "|    fps              | 3367     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71157    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 5289     |\n",
      "----------------------------------\n",
      "Num timesteps: 71200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.34\n",
      "Num timesteps: 71300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 14.77\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.322    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3824     |\n",
      "|    fps              | 3351     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71363    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00554  |\n",
      "|    n_updates        | 5340     |\n",
      "----------------------------------\n",
      "Num timesteps: 71400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.86\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3828     |\n",
      "|    fps              | 3346     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71424    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 5355     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3832     |\n",
      "|    fps              | 3342     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71484    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0573   |\n",
      "|    n_updates        | 5370     |\n",
      "----------------------------------\n",
      "Num timesteps: 71500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.74\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.8     |\n",
      "|    ep_rew_mean      | 15.8     |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3836     |\n",
      "|    fps              | 3337     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71545    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0797   |\n",
      "|    n_updates        | 5386     |\n",
      "----------------------------------\n",
      "Num timesteps: 71600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 15.81\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3840     |\n",
      "|    fps              | 3332     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71609    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0422   |\n",
      "|    n_updates        | 5402     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.1     |\n",
      "|    ep_rew_mean      | 16.1     |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3844     |\n",
      "|    fps              | 3327     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 5419     |\n",
      "----------------------------------\n",
      "Num timesteps: 71700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 16.06\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.2     |\n",
      "|    ep_rew_mean      | 16.2     |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3848     |\n",
      "|    fps              | 3321     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71750    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0398   |\n",
      "|    n_updates        | 5437     |\n",
      "----------------------------------\n",
      "Num timesteps: 71800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 16.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.3     |\n",
      "|    ep_rew_mean      | 16.3     |\n",
      "|    exploration_rate | 0.318    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3852     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71810    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0458   |\n",
      "|    n_updates        | 5452     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.5     |\n",
      "|    ep_rew_mean      | 16.5     |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3856     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71874    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 5468     |\n",
      "----------------------------------\n",
      "Num timesteps: 71900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 16.55\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.7     |\n",
      "|    ep_rew_mean      | 16.7     |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3860     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 71936    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 5483     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 72000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 16.94\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | 17       |\n",
      "|    exploration_rate | 0.316    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3864     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 72004    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0571   |\n",
      "|    n_updates        | 5500     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3868     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 72063    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 5515     |\n",
      "----------------------------------\n",
      "Num timesteps: 72100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3872     |\n",
      "|    fps              | 3294     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 72124    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0421   |\n",
      "|    n_updates        | 5530     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3876     |\n",
      "|    fps              | 3289     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 72199    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 5549     |\n",
      "----------------------------------\n",
      "Num timesteps: 72200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.46\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.314    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3880     |\n",
      "|    fps              | 3285     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 72257    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00677  |\n",
      "|    n_updates        | 5564     |\n",
      "----------------------------------\n",
      "Num timesteps: 72300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.68\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3884     |\n",
      "|    fps              | 3280     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72322    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0964   |\n",
      "|    n_updates        | 5580     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3888     |\n",
      "|    fps              | 3277     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72368    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 5591     |\n",
      "----------------------------------\n",
      "Num timesteps: 72400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.59\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3892     |\n",
      "|    fps              | 3273     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72428    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 5606     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.6     |\n",
      "|    ep_rew_mean      | 17.6     |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3896     |\n",
      "|    fps              | 3269     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72490    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0473   |\n",
      "|    n_updates        | 5622     |\n",
      "----------------------------------\n",
      "Num timesteps: 72500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.63\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.5     |\n",
      "|    ep_rew_mean      | 17.5     |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3900     |\n",
      "|    fps              | 3265     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72543    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 5635     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3904     |\n",
      "|    fps              | 3262     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72588    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 5646     |\n",
      "----------------------------------\n",
      "Num timesteps: 72600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.26\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3908     |\n",
      "|    fps              | 3259     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72632    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 5657     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | 17       |\n",
      "|    exploration_rate | 0.31     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3912     |\n",
      "|    fps              | 3256     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72675    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0341   |\n",
      "|    n_updates        | 5668     |\n",
      "----------------------------------\n",
      "Num timesteps: 72700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.08\n",
      "Num timesteps: 72800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 17.31\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 18.1     |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3916     |\n",
      "|    fps              | 3243     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 72862    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0691   |\n",
      "|    n_updates        | 5715     |\n",
      "----------------------------------\n",
      "Num timesteps: 72900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 18.13\n",
      "Num timesteps: 73000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 18.53\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.306    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3920     |\n",
      "|    fps              | 3231     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 73054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0414   |\n",
      "|    n_updates        | 5763     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 73100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 18.97\n",
      "Num timesteps: 73200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 19.43\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.304    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3924     |\n",
      "|    fps              | 3220     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 73218    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0359   |\n",
      "|    n_updates        | 5804     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.304    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3928     |\n",
      "|    fps              | 3216     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 73282    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0574   |\n",
      "|    n_updates        | 5820     |\n",
      "----------------------------------\n",
      "Num timesteps: 73300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 18.58\n",
      "Num timesteps: 73400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 19.35\n",
      "Num timesteps: 73500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.14\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3932     |\n",
      "|    fps              | 3200     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 73552    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0624   |\n",
      "|    n_updates        | 5887     |\n",
      "----------------------------------\n",
      "Num timesteps: 73600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 20.68\n",
      "Num timesteps: 73700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3936     |\n",
      "|    fps              | 3187     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 73740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0966   |\n",
      "|    n_updates        | 5934     |\n",
      "----------------------------------\n",
      "Num timesteps: 73800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.05\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3940     |\n",
      "|    fps              | 3182     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 73809    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0852   |\n",
      "|    n_updates        | 5952     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3944     |\n",
      "|    fps              | 3179     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 73869    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0598   |\n",
      "|    n_updates        | 5967     |\n",
      "----------------------------------\n",
      "Num timesteps: 73900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.85\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.298    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3948     |\n",
      "|    fps              | 3174     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 73938    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.052    |\n",
      "|    n_updates        | 5984     |\n",
      "----------------------------------\n",
      "Num timesteps: 74000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 21.90\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3952     |\n",
      "|    fps              | 3169     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74011    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0447   |\n",
      "|    n_updates        | 6002     |\n",
      "----------------------------------\n",
      "Num timesteps: 74100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.57\n",
      "Num timesteps: 74200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 22.57\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.295    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3956     |\n",
      "|    fps              | 3157     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74231    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0401   |\n",
      "|    n_updates        | 6057     |\n",
      "----------------------------------\n",
      "Num timesteps: 74300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.66\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.294    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3960     |\n",
      "|    fps              | 3152     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74305    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0268   |\n",
      "|    n_updates        | 6076     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 23.9     |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3964     |\n",
      "|    fps              | 3147     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74389    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0405   |\n",
      "|    n_updates        | 6097     |\n",
      "----------------------------------\n",
      "Num timesteps: 74400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.85\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 23.9     |\n",
      "|    exploration_rate | 0.293    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3968     |\n",
      "|    fps              | 3144     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74452    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0922   |\n",
      "|    n_updates        | 6112     |\n",
      "----------------------------------\n",
      "Num timesteps: 74500\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.93\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 23.9     |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3972     |\n",
      "|    fps              | 3139     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74515    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0774   |\n",
      "|    n_updates        | 6128     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 23.9     |\n",
      "|    exploration_rate | 0.291    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3976     |\n",
      "|    fps              | 3135     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74591    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0403   |\n",
      "|    n_updates        | 6147     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 74600\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 23.92\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.291    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3980     |\n",
      "|    fps              | 3130     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74666    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 6166     |\n",
      "----------------------------------\n",
      "Num timesteps: 74700\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 24.04\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3984     |\n",
      "|    fps              | 3126     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74733    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0954   |\n",
      "|    n_updates        | 6183     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 24.3     |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3988     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74797    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 6199     |\n",
      "----------------------------------\n",
      "Num timesteps: 74800\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 24.29\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.3     |\n",
      "|    ep_rew_mean      | 24.3     |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3992     |\n",
      "|    fps              | 3119     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 74857    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 6214     |\n",
      "----------------------------------\n",
      "Num timesteps: 74900\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 24.34\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 24.5     |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 3996     |\n",
      "|    fps              | 3114     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 74936    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 6233     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.4     |\n",
      "|    ep_rew_mean      | 24.4     |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4000     |\n",
      "|    fps              | 3111     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 74985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0653   |\n",
      "|    n_updates        | 6246     |\n",
      "----------------------------------\n",
      "Num timesteps: 75000\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 24.42\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.6     |\n",
      "|    ep_rew_mean      | 24.6     |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4004     |\n",
      "|    fps              | 3107     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 75047    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0883   |\n",
      "|    n_updates        | 6261     |\n",
      "----------------------------------\n",
      "Num timesteps: 75100\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 24.64\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 25.5     |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4008     |\n",
      "|    fps              | 3100     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 75180    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.072    |\n",
      "|    n_updates        | 6294     |\n",
      "----------------------------------\n",
      "Num timesteps: 75200\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 25.48\n",
      "Num timesteps: 75300\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 26.08\n",
      "Num timesteps: 75400\n",
      "Best mean reward: 26.16 - Last mean reward per episode: 26.67\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 27.5     |\n",
      "|    ep_rew_mean      | 27.5     |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4012     |\n",
      "|    fps              | 3086     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 75425    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 6356     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.2     |\n",
      "|    ep_rew_mean      | 26.2     |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4016     |\n",
      "|    fps              | 3083     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 75482    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 6370     |\n",
      "----------------------------------\n",
      "Num timesteps: 75500\n",
      "Best mean reward: 26.67 - Last mean reward per episode: 25.68\n",
      "Num timesteps: 75600\n",
      "Best mean reward: 26.67 - Last mean reward per episode: 26.21\n",
      "Num timesteps: 75700\n",
      "Best mean reward: 26.67 - Last mean reward per episode: 26.16\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.7     |\n",
      "|    ep_rew_mean      | 26.7     |\n",
      "|    exploration_rate | 0.281    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4020     |\n",
      "|    fps              | 3070     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 75723    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0353   |\n",
      "|    n_updates        | 6430     |\n",
      "----------------------------------\n",
      "Num timesteps: 75800\n",
      "Best mean reward: 26.67 - Last mean reward per episode: 26.09\n",
      "Num timesteps: 75900\n",
      "Best mean reward: 26.67 - Last mean reward per episode: 26.36\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 27.2     |\n",
      "|    ep_rew_mean      | 27.2     |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4024     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 75937    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0694   |\n",
      "|    n_updates        | 6484     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 27.1     |\n",
      "|    ep_rew_mean      | 27.1     |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4028     |\n",
      "|    fps              | 3056     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 75992    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 6497     |\n",
      "----------------------------------\n",
      "Num timesteps: 76000\n",
      "Best mean reward: 26.67 - Last mean reward per episode: 27.10\n",
      "Saving new best model to /tmp/gym/DQN/CartPole/best_model\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 25       |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4032     |\n",
      "|    fps              | 3052     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 76051    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0664   |\n",
      "|    n_updates        | 6512     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 76100\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 23.75\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.277    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4036     |\n",
      "|    fps              | 3048     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 76113    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 6528     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4040     |\n",
      "|    fps              | 3045     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76171    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.063    |\n",
      "|    n_updates        | 6542     |\n",
      "----------------------------------\n",
      "Num timesteps: 76200\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 23.64\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4044     |\n",
      "|    fps              | 3041     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76229    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.056    |\n",
      "|    n_updates        | 6557     |\n",
      "----------------------------------\n",
      "Num timesteps: 76300\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 23.70\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4048     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76310    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 6577     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4052     |\n",
      "|    fps              | 3033     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0995   |\n",
      "|    n_updates        | 6594     |\n",
      "----------------------------------\n",
      "Num timesteps: 76400\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 23.06\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.1     |\n",
      "|    ep_rew_mean      | 22.1     |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4056     |\n",
      "|    fps              | 3029     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76444    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0568   |\n",
      "|    n_updates        | 6610     |\n",
      "----------------------------------\n",
      "Num timesteps: 76500\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 22.10\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4060     |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76508    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0424   |\n",
      "|    n_updates        | 6626     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4064     |\n",
      "|    fps              | 3023     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76572    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0718   |\n",
      "|    n_updates        | 6642     |\n",
      "----------------------------------\n",
      "Num timesteps: 76600\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 21.83\n",
      "Num timesteps: 76700\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 22.52\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.271    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4068     |\n",
      "|    fps              | 3013     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76762    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0396   |\n",
      "|    n_updates        | 6690     |\n",
      "----------------------------------\n",
      "Num timesteps: 76800\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 23.10\n",
      "Num timesteps: 76900\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 23.79\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 24.5     |\n",
      "|    exploration_rate | 0.269    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4072     |\n",
      "|    fps              | 3003     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 76963    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 6740     |\n",
      "----------------------------------\n",
      "Num timesteps: 77000\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 24.48\n",
      "Num timesteps: 77100\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 25.28\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4076     |\n",
      "|    fps              | 2994     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 77114    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0539   |\n",
      "|    n_updates        | 6778     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4080     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 77189    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 6797     |\n",
      "----------------------------------\n",
      "Num timesteps: 77200\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 25.23\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.2     |\n",
      "|    ep_rew_mean      | 25.2     |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4084     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 77250    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 6812     |\n",
      "----------------------------------\n",
      "Num timesteps: 77300\n",
      "Best mean reward: 27.10 - Last mean reward per episode: 25.25\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 25.3     |\n",
      "|    exploration_rate | 0.265    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4088     |\n",
      "|    fps              | 2983     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 77329    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 6832     |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from logging_utils import SaveOnBestTrainingRewardCallback\n",
    "\n",
    "log_dir = \"/tmp/gym/DQN/CartPole\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", # name of your gym environement  \n",
    "               render_mode=None,#\"human\"\n",
    "              )\n",
    "env = Monitor(env, log_dir)\n",
    "\n",
    "callback = SaveOnBestTrainingRewardCallback(check_freq=100, log_dir=log_dir)\n",
    "model = DQN(\"MlpPolicy\", # type de réseaux de neuronnes \n",
    "            env, # passe l'environement\n",
    "            verbose=1, # mode verbeux ( affiche plus d'information )\n",
    "           )\n",
    "trained_model = model.learn(\n",
    "    total_timesteps=1000000, # temps d'entrainement\n",
    "    log_interval=4, # intervalle de remonter des données\n",
    "    callback=callback, # Utiliser pour stocker des métriques\n",
    ") \n",
    "# renvoie un modèle entrainé\n",
    "model.save(\"dqn_cartpole\") # sauvegarde le modèle entrainé dans un fichier\n",
    "model = DQN.load(\"dqn_cartpole\") # charge le fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb1da2",
   "metadata": {},
   "source": [
    "### Afficher la récompense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e10ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common import results_plotter\n",
    "\n",
    "# Helper from the library\n",
    "results_plotter.plot_results(\n",
    "    [log_dir], 1e5, results_plotter.X_TIMESTEPS, \"CartPole V1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging_utils import plot_results\n",
    "\n",
    "\n",
    "plot_results(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691cb59e",
   "metadata": {},
   "source": [
    "## Teste de l'agent \n",
    "\n",
    "Une fois l'agent entrainé il faut le tester et vérifier que le comportement obtenu est le bon ou proche du bon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6a9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset() # réinitialisation de l'environement \n",
    "# obs corresponds à l'observation \n",
    "# info contiens des information aditionelle\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)  # le réseaux de neuronnes choisie une action\n",
    "    obs, reward, terminated, truncated, info = env.step(action) # execute l'environemenet d'un step / d'un tour d'horloge\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506fc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
